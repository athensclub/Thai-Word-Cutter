{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athensclub/Thai-Word-Cutter/blob/master/model_with_fixed_vision_file_141_to_150.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi2hBbnAEOhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports\n",
        "from google.colab import files\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Flatten,LSTM\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "#Create a mapping from a character to an integer\n",
        "characters = 'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืฺุู฿เแโใไๅๆ็่้๊๋์ํ๎๏๐๑๒๓๔๕๖๗๘๙abcdefghijklmnopqrstuvwxyz\"\\'0123456789,.!?/\\\\:;%()[]{}+_-*@#><=^$& \\t\\n'\n",
        "char_encode = {}\n",
        "char_decode = {}\n",
        "i = 1\n",
        "for c in characters:\n",
        "  char_encode[c] = i;\n",
        "  char_decode[i] = c;\n",
        "  i += 1\n",
        "\n",
        "def encode(data):\n",
        "  encoded = []\n",
        "  data = data.lower()\n",
        "  for c in data:\n",
        "    if c in char_encode:\n",
        "      encoded.append(char_encode[c])\n",
        "    else:\n",
        "      encoded.append(0) #unknown character\n",
        "  return encoded\n",
        "\n",
        "def decode(data):\n",
        "  decoded = ''\n",
        "  for c in data:\n",
        "    if c != 0:\n",
        "      decoded = decoded + char_decode[c]\n",
        "  return decoded\n",
        "\n",
        "#convert from raw data, a text which words are splitted by '|' will be converted\n",
        "#to a list of numver encoded by function encode and a list of the position of\n",
        "#where to cut the word\n",
        "def convert_data(data):\n",
        "  splitted = data.split('|')\n",
        "  encoded = encode(data.replace('|',''))\n",
        "  ans = np.zeros(len(encoded))\n",
        "  i = 0;\n",
        "  for s in splitted:\n",
        "    if(len(s) > 0):\n",
        "      i += len(s) \n",
        "      ans[i - 1] = 1\n",
        "  return encoded,ans\n",
        "\n",
        "#create a data for model with vision of length. used for training, evaluation, and predictions\n",
        "def create_model_data(encoded,ans,length):\n",
        "  before = []\n",
        "  current = []\n",
        "  after = []\n",
        "  temp = []\n",
        "  for i in range(len(encoded)):\n",
        "    temp.append(encoded[i])\n",
        "    a = []\n",
        "    b = []\n",
        "    for x in range(length):\n",
        "      if i - x - 1 >= 0:\n",
        "        a.insert(0,encoded[i-x-1])\n",
        "      if i + x + 1 < len(encoded):\n",
        "        b.append(encoded[i+x+1])\n",
        "    before.append(a)\n",
        "    current.append(temp.copy())\n",
        "    after.append(b)\n",
        "    if ans[i] == 1:\n",
        "      temp = []\n",
        "  return sequence.pad_sequences(before,length),sequence.pad_sequences(current,length),sequence.pad_sequences(after,length)\n",
        "\n",
        "#create a model with the vision of given length\n",
        "def create_model(length):\n",
        "  num_chars = len(characters)\n",
        "\n",
        "  before_input = Input(shape=(length,), name='before')  \n",
        "  current_input = Input(shape=(length,), name='current') \n",
        "  after_input = Input(shape=(length,), name='after')  \n",
        "\n",
        "  before_features = Embedding(num_chars, 64)(before_input)\n",
        "  current_features = Embedding(num_chars, 64)(current_input)\n",
        "  after_features = Embedding(num_chars, 64)(after_input)\n",
        "\n",
        "  before_features = LSTM(128)(before_features)\n",
        "  current_features = LSTM(128)(current_features)\n",
        "  after_features = LSTM(128)(after_features)\n",
        "\n",
        "  x = Concatenate()([before_features, current_features, after_features])\n",
        "  x = Dense(128,activation='relu')(x)\n",
        "  out = Dense(1,activation='sigmoid',name='output')(x)\n",
        "\n",
        "  model = Model(inputs=[before_input, current_input, after_input],\n",
        "                    outputs=[out])\n",
        "\n",
        "  model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['acc'])\n",
        "\n",
        "  return model\n",
        "\n",
        "#train the given model with the given vision length with the given raw data\n",
        "def train(model,data,length):\n",
        "  (encoded,ans) = convert_data(data)\n",
        "  (before,current,after) = create_model_data(encoded,ans,length)\n",
        "  model.fit([before,current,after],np.asarray(ans))\n",
        "\n",
        "#evaluate the given model with the given vision length with the given raw data\n",
        "def evaluate(model,data,length):\n",
        "  (encoded,ans) = convert_data(data)\n",
        "  (before,current,after) = create_model_data(encoded,ans,length)\n",
        "  model.evaluate([before,current,after],np.asarray(ans))\n",
        "\n",
        "visions = [10,20,30,50,100,200]\n",
        "models = []\n",
        "\n",
        "for v in visions:\n",
        "  models.append(create_model(v))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfy5S9AzsMgq",
        "colab_type": "code",
        "outputId": "98589c64-87f0-403b-811f-39ec629c469f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(10):\n",
        "  target_file = open('train_{:05d}.txt'.format(i+141),'r')\n",
        "  if(target_file.mode == 'r'):\n",
        "    raw_data = target_file.read()\n",
        "  target_file.close()\n",
        "  for j in range(len(models)):\n",
        "    train(models[j],raw_data,visions[j])\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1200/1200 [==============================] - 10s 8ms/step - loss: 0.0607 - acc: 0.9774\n",
            "1200/1200 [==============================] - 11s 9ms/step - loss: 0.0680 - acc: 0.9753\n",
            "1200/1200 [==============================] - 12s 10ms/step - loss: 0.1077 - acc: 0.9616\n",
            "1200/1200 [==============================] - 15s 13ms/step - loss: 0.1073 - acc: 0.9609\n",
            "1200/1200 [==============================] - 23s 19ms/step - loss: 0.1069 - acc: 0.9619\n",
            "1200/1200 [==============================] - 39s 33ms/step - loss: 0.1065 - acc: 0.9615\n",
            "5038/5038 [==============================] - 41s 8ms/step - loss: 0.0607 - acc: 0.9777\n",
            "5038/5038 [==============================] - 46s 9ms/step - loss: 0.0672 - acc: 0.9758\n",
            "5038/5038 [==============================] - 51s 10ms/step - loss: 0.1029 - acc: 0.9617\n",
            "5038/5038 [==============================] - 64s 13ms/step - loss: 0.1024 - acc: 0.9614\n",
            "5038/5038 [==============================] - 96s 19ms/step - loss: 0.1037 - acc: 0.9613\n",
            "5038/5038 [==============================] - 163s 32ms/step - loss: 0.1028 - acc: 0.9618\n",
            "5954/5954 [==============================] - 48s 8ms/step - loss: 0.0541 - acc: 0.9799\n",
            "5954/5954 [==============================] - 55s 9ms/step - loss: 0.0628 - acc: 0.9772\n",
            "5954/5954 [==============================] - 61s 10ms/step - loss: 0.0984 - acc: 0.9635\n",
            "5954/5954 [==============================] - 76s 13ms/step - loss: 0.0982 - acc: 0.9636\n",
            "5954/5954 [==============================] - 115s 19ms/step - loss: 0.0972 - acc: 0.9640\n",
            "5954/5954 [==============================] - 193s 32ms/step - loss: 0.0976 - acc: 0.9642\n",
            "1117/1117 [==============================] - 9s 8ms/step - loss: 0.0571 - acc: 0.9781\n",
            "1117/1117 [==============================] - 10s 9ms/step - loss: 0.0647 - acc: 0.9757\n",
            "1117/1117 [==============================] - 12s 10ms/step - loss: 0.0885 - acc: 0.9677\n",
            "1117/1117 [==============================] - 14s 13ms/step - loss: 0.0896 - acc: 0.9669\n",
            "1117/1117 [==============================] - 22s 19ms/step - loss: 0.0891 - acc: 0.9679\n",
            "1117/1117 [==============================] - 36s 32ms/step - loss: 0.0891 - acc: 0.9676\n",
            "485/485 [==============================] - 4s 8ms/step - loss: 0.0399 - acc: 0.9858\n",
            "485/485 [==============================] - 4s 9ms/step - loss: 0.0469 - acc: 0.9830\n",
            "485/485 [==============================] - 5s 10ms/step - loss: 0.0722 - acc: 0.9732\n",
            "485/485 [==============================] - 6s 13ms/step - loss: 0.0704 - acc: 0.9749\n",
            "485/485 [==============================] - 9s 19ms/step - loss: 0.0680 - acc: 0.9748\n",
            "485/485 [==============================] - 16s 32ms/step - loss: 0.0707 - acc: 0.9736\n",
            "1128/1128 [==============================] - 9s 8ms/step - loss: 0.0470 - acc: 0.9827\n",
            "1128/1128 [==============================] - 11s 9ms/step - loss: 0.0519 - acc: 0.9809\n",
            "1128/1128 [==============================] - 12s 10ms/step - loss: 0.0875 - acc: 0.9674\n",
            "1128/1128 [==============================] - 14s 13ms/step - loss: 0.0859 - acc: 0.9675\n",
            "1128/1128 [==============================] - 22s 19ms/step - loss: 0.0881 - acc: 0.9678\n",
            "1128/1128 [==============================] - 37s 32ms/step - loss: 0.0830 - acc: 0.9693\n",
            "3558/3558 [==============================] - 29s 8ms/step - loss: 0.0490 - acc: 0.9820\n",
            "3558/3558 [==============================] - 33s 9ms/step - loss: 0.0575 - acc: 0.9781\n",
            "3558/3558 [==============================] - 37s 10ms/step - loss: 0.0862 - acc: 0.9666\n",
            "3558/3558 [==============================] - 46s 13ms/step - loss: 0.0865 - acc: 0.9665\n",
            "3558/3558 [==============================] - 69s 19ms/step - loss: 0.0867 - acc: 0.9669\n",
            "3558/3558 [==============================] - 116s 32ms/step - loss: 0.0867 - acc: 0.9664\n",
            "622/622 [==============================] - 5s 8ms/step - loss: 0.0526 - acc: 0.9803\n",
            "622/622 [==============================] - 6s 9ms/step - loss: 0.0616 - acc: 0.9779\n",
            "622/622 [==============================] - 6s 10ms/step - loss: 0.0880 - acc: 0.9674\n",
            "622/622 [==============================] - 8s 13ms/step - loss: 0.0871 - acc: 0.9676\n",
            "622/622 [==============================] - 12s 19ms/step - loss: 0.0896 - acc: 0.9661\n",
            "622/622 [==============================] - 20s 32ms/step - loss: 0.0885 - acc: 0.9669\n",
            "1823/1823 [==============================] - 15s 8ms/step - loss: 0.0473 - acc: 0.9827\n",
            "1823/1823 [==============================] - 17s 9ms/step - loss: 0.0560 - acc: 0.9797\n",
            "1823/1823 [==============================] - 19s 10ms/step - loss: 0.0900 - acc: 0.9659\n",
            "1823/1823 [==============================] - 24s 13ms/step - loss: 0.0877 - acc: 0.9661\n",
            "1823/1823 [==============================] - 35s 19ms/step - loss: 0.0888 - acc: 0.9661\n",
            "1823/1823 [==============================] - 59s 32ms/step - loss: 0.0883 - acc: 0.9665\n",
            "1773/1773 [==============================] - 14s 8ms/step - loss: 0.0344 - acc: 0.9883\n",
            "1773/1773 [==============================] - 16s 9ms/step - loss: 0.0452 - acc: 0.9842\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 0.0773 - acc: 0.9721\n",
            "1773/1773 [==============================] - 23s 13ms/step - loss: 0.0772 - acc: 0.9714\n",
            "1773/1773 [==============================] - 34s 19ms/step - loss: 0.0774 - acc: 0.9719\n",
            "1773/1773 [==============================] - 57s 32ms/step - loss: 0.0778 - acc: 0.9722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYDcYsIOzzLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(models)):\n",
        "  models[i].save('model_vision_' + str(visions[i]) + '.h5')\n",
        "\n",
        "for i in range(len(models)):\n",
        "  files.download('model_vision_' + str(visions[i]) + '.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
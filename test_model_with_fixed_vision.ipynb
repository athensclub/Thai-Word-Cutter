{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athensclub/Thai-Word-Cutter/blob/master/test_model_with_fixed_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHtdWPqMydYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports and files \n",
        "from google.colab import files\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Flatten,LSTM\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import time\n",
        "import numpy as np"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi2hBbnAEOhx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "0b56d686-6cf3-4b25-bde3-749e604d25fe"
      },
      "source": [
        "#Create a mapping from a character to an integer\n",
        "characters = 'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืฺุู฿เแโใไๅๆ็่้๊๋์ํ๎๏๐๑๒๓๔๕๖๗๘๙abcdefghijklmnopqrstuvwxyz\"\\'0123456789,.!?/\\\\:;%()[]{}+_-*@#><=^$& \\t\\n'\n",
        "char_encode = {}\n",
        "char_decode = {}\n",
        "i = 1\n",
        "for c in characters:\n",
        "  char_encode[c] = i;\n",
        "  char_decode[i] = c;\n",
        "  i += 1\n",
        "\n",
        "def encode(data):\n",
        "  encoded = []\n",
        "  data = data.lower()\n",
        "  for c in data:\n",
        "    if c in char_encode:\n",
        "      encoded.append(char_encode[c])\n",
        "    else:\n",
        "      encoded.append(0) #unknown character\n",
        "  return encoded\n",
        "\n",
        "def decode(data):\n",
        "  decoded = ''\n",
        "  for c in data:\n",
        "    if c != 0:\n",
        "      decoded = decoded + char_decode[c]\n",
        "  return decoded\n",
        "\n",
        "#convert from raw data, a text which words are splitted by '|' will be converted\n",
        "#to a list of numver encoded by function encode and a list of the position of\n",
        "#where to cut the word\n",
        "def convert_data(data):\n",
        "  splitted = data.split('|')\n",
        "  encoded = encode(data.replace('|',''))\n",
        "  ans = np.zeros(len(encoded))\n",
        "  i = 0;\n",
        "  for s in splitted:\n",
        "    if(len(s) > 0):\n",
        "      i += len(s) \n",
        "      ans[i - 1] = 1\n",
        "  return encoded,ans\n",
        "\n",
        "#create a data for model with vision of length. used for training, evaluation, and predictions\n",
        "def create_model_data(encoded,ans,length):\n",
        "  before = []\n",
        "  current = []\n",
        "  after = []\n",
        "  temp = []\n",
        "  for i in range(len(encoded)):\n",
        "    temp.append(encoded[i])\n",
        "    a = []\n",
        "    b = []\n",
        "    for x in range(length):\n",
        "      if i - x - 1 >= 0:\n",
        "        a.insert(0,encoded[i-x-1])\n",
        "      if i + x + 1 < len(encoded):\n",
        "        b.append(encoded[i+x+1])\n",
        "    before.append(a)\n",
        "    current.append(temp.copy())\n",
        "    after.append(b)\n",
        "    if ans[i] == 1:\n",
        "      temp = []\n",
        "  return sequence.pad_sequences(before,length),sequence.pad_sequences(current,length),sequence.pad_sequences(after,length)\n",
        "\n",
        "#train the given model with the given vision length with the given raw data\n",
        "def train(model,data,length):\n",
        "  (encoded,ans) = convert_data(data)\n",
        "  (before,current,after) = create_model_data(encoded,ans,length)\n",
        "  model.fit([before,current,after],np.asarray(ans))\n",
        "\n",
        "def timed(func):\n",
        "   def function_timer(*args, **kwargs):\n",
        "      start = time.time()\n",
        "      value = func(*args, **kwargs)\n",
        "      end = time.time()\n",
        "      runtime = end - start\n",
        "      msg = \"{func} took {time} seconds to complete its execution.\"\n",
        "      print(msg.format(func = func.__name__,time = runtime))\n",
        "      print(value)\n",
        "   return function_timer\n",
        "\n",
        "#evaluate the given model with the given vision length with the given raw data\n",
        "@timed\n",
        "def evaluate(model,data,length):\n",
        "  (encoded,ans) = convert_data(data)\n",
        "  (before,current,after) = create_model_data(encoded,ans,length)\n",
        "  return model.evaluate([before,current,after],np.asarray(ans))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "visions = [10,20,30,50,100,200]\n",
        "models = []\n",
        "\n",
        "for v in visions:\n",
        "  models.append(load_model('model_vision_' + str(v) + '.h5'))\n",
        "raw_data = \"\";\n",
        "for i in range(5):\n",
        "  target_file = open('train_{:05d}.txt'.format(445+1),'r')\n",
        "  if(target_file.mode == 'r'):\n",
        "    raw_data += target_file.read()\n",
        "  target_file.close()\n",
        "\n",
        "for j in range(len(models)):\n",
        "  print('vision ' + str(visions[j]) + ': ')\n",
        "  evaluate(models[j],raw_data,visions[j])\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vision 10: \n",
            "2374/2374 [==============================] - 15s 6ms/step - loss: 0.0507 - acc: 0.9812\n",
            "evaluate took 18.452951669692993 seconds to complete its execution.\n",
            "[0.05072725564241409, 0.9812352061271667]\n",
            "vision 20: \n",
            "2374/2374 [==============================] - 19s 8ms/step - loss: 0.0615 - acc: 0.9761\n",
            "evaluate took 23.239840269088745 seconds to complete its execution.\n",
            "[0.06153349205851555, 0.9760732054710388]\n",
            "vision 30: \n",
            "2374/2374 [==============================] - 25s 11ms/step - loss: 0.1072 - acc: 0.9586\n",
            "evaluate took 30.30086922645569 seconds to complete its execution.\n",
            "[0.1072482019662857, 0.9585857391357422]\n",
            "vision 50: \n",
            "2374/2374 [==============================] - 36s 15ms/step - loss: 0.1055 - acc: 0.9584\n",
            "evaluate took 45.074501752853394 seconds to complete its execution.\n",
            "[0.10546562075614929, 0.9583882093429565]\n",
            "vision 100: \n",
            "2374/2374 [==============================] - 63s 27ms/step - loss: 0.1001 - acc: 0.9592\n",
            "evaluate took 72.32821106910706 seconds to complete its execution.\n",
            "[0.10011348873376846, 0.9592441320419312]\n",
            "vision 200: \n",
            "2374/2374 [==============================] - 117s 49ms/step - loss: 0.1027 - acc: 0.9588\n",
            "evaluate took 132.64933848381042 seconds to complete its execution.\n",
            "[0.10267859697341919, 0.9587832689285278]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd1S-gz7duRr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "15e2d071-7c7d-4739-fdb0-a1089b3685d2"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153120\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
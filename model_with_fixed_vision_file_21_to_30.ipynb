{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMHmzkr008qtW1Wn+JoswxX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athensclub/Thai-Word-Cutter/blob/master/model_with_fixed_vision_file_21_to_30.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi2hBbnAEOhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports\n",
        "from google.colab import files\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Flatten,LSTM\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "#Create a mapping from a character to an integer\n",
        "characters = 'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืฺุู฿เแโใไๅๆ็่้๊๋์ํ๎๏๐๑๒๓๔๕๖๗๘๙abcdefghijklmnopqrstuvwxyz\"\\'0123456789,.!?/\\\\:;%()[]{}+_-*@#><=^$& \\t\\n'\n",
        "char_encode = {}\n",
        "char_decode = {}\n",
        "i = 1\n",
        "for c in characters:\n",
        "  char_encode[c] = i;\n",
        "  char_decode[i] = c;\n",
        "  i += 1\n",
        "\n",
        "def encode(data):\n",
        "  encoded = []\n",
        "  data = data.lower()\n",
        "  for c in data:\n",
        "    if c in char_encode:\n",
        "      encoded.append(char_encode[c])\n",
        "    else:\n",
        "      encoded.append(0) #unknown character\n",
        "  return encoded\n",
        "\n",
        "def decode(data):\n",
        "  decoded = ''\n",
        "  for c in data:\n",
        "    if c != 0:\n",
        "      decoded = decoded + char_decode[c]\n",
        "  return decoded\n",
        "\n",
        "#convert from raw data, a text which words are splitted by '|' will be converted\n",
        "#to a list of numver encoded by function encode and a list of the position of\n",
        "#where to cut the word\n",
        "def convert_data(data):\n",
        "  splitted = data.split('|')\n",
        "  encoded = encode(data.replace('|',''))\n",
        "  ans = np.zeros(len(encoded))\n",
        "  i = 0;\n",
        "  for s in splitted:\n",
        "    if(len(s) > 0):\n",
        "      i += len(s) \n",
        "      ans[i - 1] = 1\n",
        "  return encoded,ans\n",
        "\n",
        "#create a data for model with vision of length. used for training, evaluation, and predictions\n",
        "def create_model_data(encoded,ans,length):\n",
        "  before = []\n",
        "  current = []\n",
        "  after = []\n",
        "  temp = []\n",
        "  for i in range(len(encoded)):\n",
        "    temp.append(encoded[i])\n",
        "    a = []\n",
        "    b = []\n",
        "    for x in range(length):\n",
        "      if i - x - 1 >= 0:\n",
        "        a.insert(0,encoded[i-x-1])\n",
        "      if i + x + 1 < len(encoded):\n",
        "        b.append(encoded[i+x+1])\n",
        "    before.append(a)\n",
        "    current.append(temp.copy())\n",
        "    after.append(b)\n",
        "    if ans[i] == 1:\n",
        "      temp = []\n",
        "  return sequence.pad_sequences(before,length),sequence.pad_sequences(current,length),sequence.pad_sequences(after,length)\n",
        "\n",
        "#create a model with the vision of given length\n",
        "def create_model(length):\n",
        "  num_chars = len(characters)\n",
        "\n",
        "  before_input = Input(shape=(length,), name='before')  \n",
        "  current_input = Input(shape=(length,), name='current') \n",
        "  after_input = Input(shape=(length,), name='after')  \n",
        "\n",
        "  before_features = Embedding(num_chars, 64)(before_input)\n",
        "  current_features = Embedding(num_chars, 64)(current_input)\n",
        "  after_features = Embedding(num_chars, 64)(after_input)\n",
        "\n",
        "  before_features = LSTM(128)(before_features)\n",
        "  current_features = LSTM(128)(current_features)\n",
        "  after_features = LSTM(128)(after_features)\n",
        "\n",
        "  x = Concatenate()([before_features, current_features, after_features])\n",
        "  x = Dense(128,activation='relu')(x)\n",
        "  out = Dense(1,activation='sigmoid',name='output')(x)\n",
        "\n",
        "  model = Model(inputs=[before_input, current_input, after_input],\n",
        "                    outputs=[out])\n",
        "\n",
        "  model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['acc'])\n",
        "\n",
        "  return model\n",
        "\n",
        "#train the given model with the given vision length with the given raw data\n",
        "def train(model,data,length):\n",
        "  (encoded,ans) = convert_data(data)\n",
        "  (before,current,after) = create_model_data(encoded,ans,length)\n",
        "  model.fit([before,current,after],np.asarray(ans))\n",
        "\n",
        "#evaluate the given model with the given vision length with the given raw data\n",
        "def evaluate(model,data,length):\n",
        "  (encoded,ans) = convert_data(data)\n",
        "  (before,current,after) = create_model_data(encoded,ans,length)\n",
        "  model.evaluate([before,current,after],np.asarray(ans))\n",
        "\n",
        "visions = [10,20,30,50,100,200]\n",
        "models = []\n",
        "\n",
        "for v in visions:\n",
        "  models.append(create_model(v))\n",
        "\n",
        "for i in range(10):\n",
        "  target_file = open('train_{:05d}.txt'.format(i+11),'r')\n",
        "  if(target_file.mode == 'r'):\n",
        "    raw_data = target_file.read()\n",
        "  target_file.close()\n",
        "  for j in range(len(models)):\n",
        "    train(models[j],raw_data,visions[j])\n",
        "\n",
        "for i in range(len(models)):\n",
        "  models[i].save('model_vision_' + str(visions[i]) + '.h5')\n",
        "\n",
        "for i in range(len(models)):\n",
        "  files.download('model_vision_' + str(visions[i]) + '.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfy5S9AzsMgq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "59176f18-77f2-4ede-915d-674b49d45c42"
      },
      "source": [
        "for i in range(10):\n",
        "  target_file = open('train_{:05d}.txt'.format(i+21),'r')\n",
        "  if(target_file.mode == 'r'):\n",
        "    raw_data = target_file.read()\n",
        "  target_file.close()\n",
        "  for j in range(len(models)):\n",
        "    train(models[j],raw_data,visions[j])\n",
        "\n",
        "for i in range(len(models)):\n",
        "  models[i].save('model_vision_' + str(visions[i]) + '.h5')\n",
        "\n",
        "for i in range(len(models)):\n",
        "  files.download('model_vision_' + str(visions[i]) + '.h5')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1005/1005 [==============================] - 9s 9ms/step - loss: 0.0651 - acc: 0.9766\n",
            "1005/1005 [==============================] - 10s 10ms/step - loss: 0.0695 - acc: 0.9752\n",
            "1005/1005 [==============================] - 11s 11ms/step - loss: 0.0998 - acc: 0.9641\n",
            "1005/1005 [==============================] - 14s 14ms/step - loss: 0.0992 - acc: 0.9651\n",
            "1005/1005 [==============================] - 18s 18ms/step - loss: 0.1001 - acc: 0.9640\n",
            "1005/1005 [==============================] - 29s 29ms/step - loss: 0.0991 - acc: 0.9639\n",
            "305/305 [==============================] - 3s 9ms/step - loss: 0.0655 - acc: 0.9764\n",
            "305/305 [==============================] - 3s 10ms/step - loss: 0.0654 - acc: 0.9743\n",
            "305/305 [==============================] - 3s 11ms/step - loss: 0.0966 - acc: 0.9623\n",
            "305/305 [==============================] - 4s 13ms/step - loss: 0.0966 - acc: 0.9646\n",
            "305/305 [==============================] - 6s 18ms/step - loss: 0.0999 - acc: 0.9617\n",
            "305/305 [==============================] - 9s 29ms/step - loss: 0.0975 - acc: 0.9665\n",
            "539/539 [==============================] - 5s 9ms/step - loss: 0.0658 - acc: 0.9763\n",
            "539/539 [==============================] - 5s 10ms/step - loss: 0.0670 - acc: 0.9754\n",
            "539/539 [==============================] - 6s 12ms/step - loss: 0.1152 - acc: 0.9559\n",
            "539/539 [==============================] - 7s 13ms/step - loss: 0.1145 - acc: 0.9577\n",
            "539/539 [==============================] - 10s 18ms/step - loss: 0.1162 - acc: 0.9558\n",
            "539/539 [==============================] - 16s 29ms/step - loss: 0.1164 - acc: 0.9560\n",
            "1436/1436 [==============================] - 13s 9ms/step - loss: 0.0631 - acc: 0.9774\n",
            "1436/1436 [==============================] - 14s 10ms/step - loss: 0.0715 - acc: 0.9744\n",
            "1436/1436 [==============================] - 16s 11ms/step - loss: 0.1043 - acc: 0.9595\n",
            "1436/1436 [==============================] - 19s 13ms/step - loss: 0.1027 - acc: 0.9610\n",
            "1436/1436 [==============================] - 26s 18ms/step - loss: 0.1065 - acc: 0.9598\n",
            "1436/1436 [==============================] - 42s 29ms/step - loss: 0.1056 - acc: 0.9594\n",
            "291/291 [==============================] - 3s 9ms/step - loss: 0.0818 - acc: 0.9707\n",
            "291/291 [==============================] - 3s 10ms/step - loss: 0.0840 - acc: 0.9686\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.1175 - acc: 0.9555\n",
            "291/291 [==============================] - 4s 14ms/step - loss: 0.1157 - acc: 0.9555\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.1189 - acc: 0.9565\n",
            "291/291 [==============================] - 8s 29ms/step - loss: 0.1152 - acc: 0.9562\n",
            "1923/1923 [==============================] - 17s 9ms/step - loss: 0.0747 - acc: 0.9721\n",
            "1923/1923 [==============================] - 20s 10ms/step - loss: 0.0810 - acc: 0.9685\n",
            "1923/1923 [==============================] - 22s 12ms/step - loss: 0.1079 - acc: 0.9591\n",
            "1923/1923 [==============================] - 26s 13ms/step - loss: 0.1047 - acc: 0.9602\n",
            "1923/1923 [==============================] - 36s 19ms/step - loss: 0.1083 - acc: 0.9589\n",
            "1923/1923 [==============================] - 56s 29ms/step - loss: 0.1075 - acc: 0.9586\n",
            "1532/1532 [==============================] - 13s 8ms/step - loss: 0.0664 - acc: 0.9756\n",
            "1532/1532 [==============================] - 14s 9ms/step - loss: 0.0712 - acc: 0.9730\n",
            "1532/1532 [==============================] - 17s 11ms/step - loss: 0.1065 - acc: 0.9592\n",
            "1532/1532 [==============================] - 20s 13ms/step - loss: 0.1053 - acc: 0.9598\n",
            "1532/1532 [==============================] - 27s 18ms/step - loss: 0.1070 - acc: 0.9591\n",
            "1532/1532 [==============================] - 44s 28ms/step - loss: 0.1061 - acc: 0.9598\n",
            "1474/1474 [==============================] - 13s 9ms/step - loss: 0.0574 - acc: 0.9782\n",
            "1474/1474 [==============================] - 15s 10ms/step - loss: 0.0616 - acc: 0.9769\n",
            "1474/1474 [==============================] - 17s 12ms/step - loss: 0.0946 - acc: 0.9642\n",
            "1474/1474 [==============================] - 20s 14ms/step - loss: 0.0922 - acc: 0.9651\n",
            "1474/1474 [==============================] - 28s 19ms/step - loss: 0.0924 - acc: 0.9658\n",
            "1474/1474 [==============================] - 43s 29ms/step - loss: 0.0933 - acc: 0.9655\n",
            "889/889 [==============================] - 8s 9ms/step - loss: 0.0552 - acc: 0.9817\n",
            "889/889 [==============================] - 9s 10ms/step - loss: 0.0610 - acc: 0.9796\n",
            "889/889 [==============================] - 10s 12ms/step - loss: 0.0930 - acc: 0.9691\n",
            "889/889 [==============================] - 12s 14ms/step - loss: 0.0932 - acc: 0.9678\n",
            "889/889 [==============================] - 16s 19ms/step - loss: 0.0930 - acc: 0.9684\n",
            "889/889 [==============================] - 26s 29ms/step - loss: 0.0927 - acc: 0.9683\n",
            "2172/2172 [==============================] - 18s 9ms/step - loss: 0.0603 - acc: 0.9770\n",
            "2172/2172 [==============================] - 21s 10ms/step - loss: 0.0649 - acc: 0.9747\n",
            "2172/2172 [==============================] - 24s 11ms/step - loss: 0.0988 - acc: 0.9622\n",
            "2172/2172 [==============================] - 29s 13ms/step - loss: 0.0972 - acc: 0.9630\n",
            "2172/2172 [==============================] - 39s 18ms/step - loss: 0.1008 - acc: 0.9616\n",
            "2172/2172 [==============================] - 63s 29ms/step - loss: 0.0977 - acc: 0.9627\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ae8ec4d01bbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_vision_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: NetworkError when attempting to fetch resource."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYDcYsIOzzLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(models)):\n",
        "  models[i].save('model_vision_' + str(visions[i]) + '.h5')\n",
        "\n",
        "for i in range(len(models)):\n",
        "  files.download('model_vision_' + str(visions[i]) + '.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
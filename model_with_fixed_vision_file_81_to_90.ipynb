{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athensclub/Thai-Word-Cutter/blob/master/model_with_fixed_vision_file_81_to_90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi2hBbnAEOhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports\n",
        "from google.colab import files\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Flatten,LSTM\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "#Create a mapping from a character to an integer\n",
        "characters = 'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืฺุู฿เแโใไๅๆ็่้๊๋์ํ๎๏๐๑๒๓๔๕๖๗๘๙abcdefghijklmnopqrstuvwxyz\"\\'0123456789,.!?/\\\\:;%()[]{}+_-*@#><=^$& \\t\\n'\n",
        "char_encode = {}\n",
        "char_decode = {}\n",
        "i = 1\n",
        "for c in characters:\n",
        "  char_encode[c] = i;\n",
        "  char_decode[i] = c;\n",
        "  i += 1\n",
        "\n",
        "def encode(data):\n",
        "  encoded = []\n",
        "  data = data.lower()\n",
        "  for c in data:\n",
        "    if c in char_encode:\n",
        "      encoded.append(char_encode[c])\n",
        "    else:\n",
        "      encoded.append(0) #unknown character\n",
        "  return encoded\n",
        "\n",
        "def decode(data):\n",
        "  decoded = ''\n",
        "  for c in data:\n",
        "    if c != 0:\n",
        "      decoded = decoded + char_decode[c]\n",
        "  return decoded\n",
        "\n",
        "#convert from raw data, a text which words are splitted by '|' will be converted\n",
        "#to a list of numver encoded by function encode and a list of the position of\n",
        "#where to cut the word\n",
        "def convert_data(data):\n",
        "  splitted = data.split('|')\n",
        "  encoded = encode(data.replace('|',''))\n",
        "  ans = np.zeros(len(encoded))\n",
        "  i = 0;\n",
        "  for s in splitted:\n",
        "    if(len(s) > 0):\n",
        "      i += len(s) \n",
        "      ans[i - 1] = 1\n",
        "  return encoded,ans\n",
        "\n",
        "#create a data for model with vision of length. used for training, evaluation, and predictions\n",
        "def create_model_data(encoded,ans,length):\n",
        "  before = []\n",
        "  current = []\n",
        "  after = []\n",
        "  temp = []\n",
        "  for i in range(len(encoded)):\n",
        "    temp.append(encoded[i])\n",
        "    a = []\n",
        "    b = []\n",
        "    for x in range(length):\n",
        "      if i - x - 1 >= 0:\n",
        "        a.insert(0,encoded[i-x-1])\n",
        "      if i + x + 1 < len(encoded):\n",
        "        b.append(encoded[i+x+1])\n",
        "    before.append(a)\n",
        "    current.append(temp.copy())\n",
        "    after.append(b)\n",
        "    if ans[i] == 1:\n",
        "      temp = []\n",
        "  return sequence.pad_sequences(before,length),sequence.pad_sequences(current,length),sequence.pad_sequences(after,length)\n",
        "\n",
        "#create a model with the vision of given length\n",
        "def create_model(length):\n",
        "  num_chars = len(characters)\n",
        "\n",
        "  before_input = Input(shape=(length,), name='before')  \n",
        "  current_input = Input(shape=(length,), name='current') \n",
        "  after_input = Input(shape=(length,), name='after')  \n",
        "\n",
        "  before_features = Embedding(num_chars, 64)(before_input)\n",
        "  current_features = Embedding(num_chars, 64)(current_input)\n",
        "  after_features = Embedding(num_chars, 64)(after_input)\n",
        "\n",
        "  before_features = LSTM(128)(before_features)\n",
        "  current_features = LSTM(128)(current_features)\n",
        "  after_features = LSTM(128)(after_features)\n",
        "\n",
        "  x = Concatenate()([before_features, current_features, after_features])\n",
        "  x = Dense(128,activation='relu')(x)\n",
        "  out = Dense(1,activation='sigmoid',name='output')(x)\n",
        "\n",
        "  model = Model(inputs=[before_input, current_input, after_input],\n",
        "                    outputs=[out])\n",
        "\n",
        "  model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['acc'])\n",
        "\n",
        "  return model\n",
        "\n",
        "#train the given model with the given vision length with the given raw data\n",
        "def train(model,data,length):\n",
        "  (encoded,ans) = convert_data(data)\n",
        "  (before,current,after) = create_model_data(encoded,ans,length)\n",
        "  model.fit([before,current,after],np.asarray(ans))\n",
        "\n",
        "#evaluate the given model with the given vision length with the given raw data\n",
        "def evaluate(model,data,length):\n",
        "  (encoded,ans) = convert_data(data)\n",
        "  (before,current,after) = create_model_data(encoded,ans,length)\n",
        "  model.evaluate([before,current,after],np.asarray(ans))\n",
        "\n",
        "visions = [10,20,30,50,100,200]\n",
        "models = []\n",
        "\n",
        "for v in visions:\n",
        "  models.append(create_model(v))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfy5S9AzsMgq",
        "colab_type": "code",
        "outputId": "b1c51e73-4a7e-41b2-856b-37db97e1c684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(10):\n",
        "  target_file = open('train_{:05d}.txt'.format(i+81),'r')\n",
        "  if(target_file.mode == 'r'):\n",
        "    raw_data = target_file.read()\n",
        "  target_file.close()\n",
        "  for j in range(len(models)):\n",
        "    train(models[j],raw_data,visions[j])\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1395/1395 [==============================] - 11s 8ms/step - loss: 0.0276 - acc: 0.9899\n",
            "1395/1395 [==============================] - 12s 9ms/step - loss: 0.0295 - acc: 0.9893\n",
            "1395/1395 [==============================] - 14s 10ms/step - loss: 0.0696 - acc: 0.9742\n",
            "1395/1395 [==============================] - 19s 13ms/step - loss: 0.0697 - acc: 0.9738\n",
            "1395/1395 [==============================] - 31s 22ms/step - loss: 0.0686 - acc: 0.9737\n",
            "1395/1395 [==============================] - 57s 41ms/step - loss: 0.0693 - acc: 0.9746\n",
            "845/845 [==============================] - 7s 8ms/step - loss: 0.0198 - acc: 0.9929\n",
            "845/845 [==============================] - 7s 9ms/step - loss: 0.0229 - acc: 0.9923\n",
            "845/845 [==============================] - 8s 10ms/step - loss: 0.0500 - acc: 0.9815\n",
            "845/845 [==============================] - 11s 13ms/step - loss: 0.0502 - acc: 0.9806\n",
            "845/845 [==============================] - 19s 22ms/step - loss: 0.0524 - acc: 0.9813\n",
            "845/845 [==============================] - 34s 41ms/step - loss: 0.0493 - acc: 0.9813\n",
            "1310/1310 [==============================] - 10s 8ms/step - loss: 0.0349 - acc: 0.9871\n",
            "1310/1310 [==============================] - 11s 9ms/step - loss: 0.0385 - acc: 0.9856\n",
            "1310/1310 [==============================] - 13s 10ms/step - loss: 0.0674 - acc: 0.9745\n",
            "1310/1310 [==============================] - 17s 13ms/step - loss: 0.0689 - acc: 0.9741\n",
            "1310/1310 [==============================] - 29s 22ms/step - loss: 0.0670 - acc: 0.9743\n",
            "1310/1310 [==============================] - 54s 41ms/step - loss: 0.0685 - acc: 0.9742\n",
            "1778/1778 [==============================] - 14s 8ms/step - loss: 0.0378 - acc: 0.9858\n",
            "1778/1778 [==============================] - 16s 9ms/step - loss: 0.0426 - acc: 0.9838\n",
            "1778/1778 [==============================] - 17s 10ms/step - loss: 0.0742 - acc: 0.9704\n",
            "1778/1778 [==============================] - 23s 13ms/step - loss: 0.0746 - acc: 0.9715\n",
            "1778/1778 [==============================] - 39s 22ms/step - loss: 0.0736 - acc: 0.9717\n",
            "1778/1778 [==============================] - 72s 41ms/step - loss: 0.0735 - acc: 0.9721\n",
            "1140/1140 [==============================] - 9s 8ms/step - loss: 0.0191 - acc: 0.9935\n",
            "1140/1140 [==============================] - 10s 9ms/step - loss: 0.0204 - acc: 0.9935\n",
            "1140/1140 [==============================] - 11s 10ms/step - loss: 0.0470 - acc: 0.9812\n",
            "1140/1140 [==============================] - 15s 13ms/step - loss: 0.0476 - acc: 0.9808\n",
            "1140/1140 [==============================] - 25s 22ms/step - loss: 0.0477 - acc: 0.9814\n",
            "1140/1140 [==============================] - 47s 41ms/step - loss: 0.0465 - acc: 0.9821\n",
            "1735/1735 [==============================] - 13s 8ms/step - loss: 0.0299 - acc: 0.9889\n",
            "1735/1735 [==============================] - 15s 9ms/step - loss: 0.0341 - acc: 0.9877\n",
            "1735/1735 [==============================] - 17s 10ms/step - loss: 0.0680 - acc: 0.9738\n",
            "1735/1735 [==============================] - 23s 13ms/step - loss: 0.0681 - acc: 0.9731\n",
            "1735/1735 [==============================] - 38s 22ms/step - loss: 0.0665 - acc: 0.9737\n",
            "1735/1735 [==============================] - 71s 41ms/step - loss: 0.0674 - acc: 0.9736\n",
            "2522/2522 [==============================] - 19s 8ms/step - loss: 0.0252 - acc: 0.9909\n",
            "2522/2522 [==============================] - 22s 9ms/step - loss: 0.0284 - acc: 0.9897\n",
            "2522/2522 [==============================] - 25s 10ms/step - loss: 0.0785 - acc: 0.9697\n",
            "2522/2522 [==============================] - 33s 13ms/step - loss: 0.0822 - acc: 0.9680\n",
            "2522/2522 [==============================] - 55s 22ms/step - loss: 0.0821 - acc: 0.9688\n",
            "2522/2522 [==============================] - 103s 41ms/step - loss: 0.0814 - acc: 0.9690\n",
            "2183/2183 [==============================] - 17s 8ms/step - loss: 0.0362 - acc: 0.9874\n",
            "2183/2183 [==============================] - 19s 9ms/step - loss: 0.0368 - acc: 0.9872\n",
            "2183/2183 [==============================] - 21s 10ms/step - loss: 0.0764 - acc: 0.9706\n",
            "2183/2183 [==============================] - 28s 13ms/step - loss: 0.0778 - acc: 0.9705\n",
            "2183/2183 [==============================] - 48s 22ms/step - loss: 0.0768 - acc: 0.9704\n",
            "2183/2183 [==============================] - 89s 41ms/step - loss: 0.0766 - acc: 0.9707\n",
            "1355/1355 [==============================] - 10s 8ms/step - loss: 0.0572 - acc: 0.9798\n",
            "1355/1355 [==============================] - 12s 9ms/step - loss: 0.0573 - acc: 0.9791\n",
            "1355/1355 [==============================] - 13s 10ms/step - loss: 0.1003 - acc: 0.9617\n",
            "1355/1355 [==============================] - 18s 13ms/step - loss: 0.0987 - acc: 0.9621\n",
            "1355/1355 [==============================] - 30s 22ms/step - loss: 0.0988 - acc: 0.9631\n",
            "1355/1355 [==============================] - 55s 41ms/step - loss: 0.0998 - acc: 0.9620\n",
            "591/591 [==============================] - 5s 8ms/step - loss: 0.0421 - acc: 0.9854\n",
            "591/591 [==============================] - 5s 9ms/step - loss: 0.0436 - acc: 0.9839\n",
            "591/591 [==============================] - 6s 10ms/step - loss: 0.1039 - acc: 0.9599\n",
            "591/591 [==============================] - 8s 13ms/step - loss: 0.1044 - acc: 0.9611\n",
            "591/591 [==============================] - 13s 22ms/step - loss: 0.1035 - acc: 0.9609\n",
            "591/591 [==============================] - 24s 41ms/step - loss: 0.1041 - acc: 0.9603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYDcYsIOzzLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(models)):\n",
        "  models[i].save('model_vision_' + str(visions[i]) + '.h5')\n",
        "\n",
        "for i in range(len(models)):\n",
        "  files.download('model_vision_' + str(visions[i]) + '.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athensclub/Thai-Word-Cutter/blob/master/model_with_fixed_vision_file_41_to_50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi2hBbnAEOhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports\n",
        "from google.colab import files\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Flatten,LSTM\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "#Create a mapping from a character to an integer\n",
        "characters = 'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืฺุู฿เแโใไๅๆ็่้๊๋์ํ๎๏๐๑๒๓๔๕๖๗๘๙abcdefghijklmnopqrstuvwxyz\"\\'0123456789,.!?/\\\\:;%()[]{}+_-*@#><=^$& \\t\\n'\n",
        "char_encode = {}\n",
        "char_decode = {}\n",
        "i = 1\n",
        "for c in characters:\n",
        "  char_encode[c] = i;\n",
        "  char_decode[i] = c;\n",
        "  i += 1\n",
        "\n",
        "def encode(data):\n",
        "  encoded = []\n",
        "  data = data.lower()\n",
        "  for c in data:\n",
        "    if c in char_encode:\n",
        "      encoded.append(char_encode[c])\n",
        "    else:\n",
        "      encoded.append(0) #unknown character\n",
        "  return encoded\n",
        "\n",
        "def decode(data):\n",
        "  decoded = ''\n",
        "  for c in data:\n",
        "    if c != 0:\n",
        "      decoded = decoded + char_decode[c]\n",
        "  return decoded\n",
        "\n",
        "#convert from raw data, a text which words are splitted by '|' will be converted\n",
        "#to a list of numver encoded by function encode and a list of the position of\n",
        "#where to cut the word\n",
        "def convert_data(data):\n",
        "  splitted = data.split('|')\n",
        "  encoded = encode(data.replace('|',''))\n",
        "  ans = np.zeros(len(encoded))\n",
        "  i = 0;\n",
        "  for s in splitted:\n",
        "    if(len(s) > 0):\n",
        "      i += len(s) \n",
        "      ans[i - 1] = 1\n",
        "  return encoded,ans\n",
        "\n",
        "#create a data for model with vision of length. used for training, evaluation, and predictions\n",
        "def create_model_data(encoded,ans,length):\n",
        "  before = []\n",
        "  current = []\n",
        "  after = []\n",
        "  temp = []\n",
        "  for i in range(len(encoded)):\n",
        "    temp.append(encoded[i])\n",
        "    a = []\n",
        "    b = []\n",
        "    for x in range(length):\n",
        "      if i - x - 1 >= 0:\n",
        "        a.insert(0,encoded[i-x-1])\n",
        "      if i + x + 1 < len(encoded):\n",
        "        b.append(encoded[i+x+1])\n",
        "    before.append(a)\n",
        "    current.append(temp.copy())\n",
        "    after.append(b)\n",
        "    if ans[i] == 1:\n",
        "      temp = []\n",
        "  return sequence.pad_sequences(before,length),sequence.pad_sequences(current,length),sequence.pad_sequences(after,length)\n",
        "\n",
        "#create a model with the vision of given length\n",
        "def create_model(length):\n",
        "  num_chars = len(characters)\n",
        "\n",
        "  before_input = Input(shape=(length,), name='before')  \n",
        "  current_input = Input(shape=(length,), name='current') \n",
        "  after_input = Input(shape=(length,), name='after')  \n",
        "\n",
        "  before_features = Embedding(num_chars, 64)(before_input)\n",
        "  current_features = Embedding(num_chars, 64)(current_input)\n",
        "  after_features = Embedding(num_chars, 64)(after_input)\n",
        "\n",
        "  before_features = LSTM(128)(before_features)\n",
        "  current_features = LSTM(128)(current_features)\n",
        "  after_features = LSTM(128)(after_features)\n",
        "\n",
        "  x = Concatenate()([before_features, current_features, after_features])\n",
        "  x = Dense(128,activation='relu')(x)\n",
        "  out = Dense(1,activation='sigmoid',name='output')(x)\n",
        "\n",
        "  model = Model(inputs=[before_input, current_input, after_input],\n",
        "                    outputs=[out])\n",
        "\n",
        "  model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['acc'])\n",
        "\n",
        "  return model\n",
        "\n",
        "#train the given model with the given vision length with the given raw data\n",
        "def train(model,data,length):\n",
        "  (encoded,ans) = convert_data(data)\n",
        "  (before,current,after) = create_model_data(encoded,ans,length)\n",
        "  model.fit([before,current,after],np.asarray(ans))\n",
        "\n",
        "#evaluate the given model with the given vision length with the given raw data\n",
        "def evaluate(model,data,length):\n",
        "  (encoded,ans) = convert_data(data)\n",
        "  (before,current,after) = create_model_data(encoded,ans,length)\n",
        "  model.evaluate([before,current,after],np.asarray(ans))\n",
        "\n",
        "visions = [10,20,30,50,100,200]\n",
        "models = []\n",
        "\n",
        "for v in visions:\n",
        "  models.append(create_model(v))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfy5S9AzsMgq",
        "colab_type": "code",
        "outputId": "3e44b182-b9f2-45f1-d442-5bc67436c0de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(10):\n",
        "  target_file = open('train_{:05d}.txt'.format(i+41),'r')\n",
        "  if(target_file.mode == 'r'):\n",
        "    raw_data = target_file.read()\n",
        "  target_file.close()\n",
        "  for j in range(len(models)):\n",
        "    train(models[j],raw_data,visions[j])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "792/792 [==============================] - 7s 9ms/step - loss: 0.2661 - acc: 0.8904\n",
            "792/792 [==============================] - 8s 10ms/step - loss: 0.2880 - acc: 0.8838\n",
            "792/792 [==============================] - 9s 11ms/step - loss: 0.2945 - acc: 0.8808\n",
            "792/792 [==============================] - 11s 14ms/step - loss: 0.2913 - acc: 0.8814\n",
            "792/792 [==============================] - 18s 22ms/step - loss: 0.2913 - acc: 0.8827\n",
            "792/792 [==============================] - 33s 42ms/step - loss: 0.2920 - acc: 0.8801\n",
            "1708/1708 [==============================] - 14s 8ms/step - loss: 0.1671 - acc: 0.9343\n",
            "1708/1708 [==============================] - 16s 9ms/step - loss: 0.2156 - acc: 0.9122\n",
            "1708/1708 [==============================] - 18s 11ms/step - loss: 0.2333 - acc: 0.9036\n",
            "1708/1708 [==============================] - 23s 14ms/step - loss: 0.2413 - acc: 0.9012\n",
            "1708/1708 [==============================] - 38s 22ms/step - loss: 0.2330 - acc: 0.9064\n",
            "1708/1708 [==============================] - 70s 41ms/step - loss: 0.2342 - acc: 0.9042\n",
            "466/466 [==============================] - 4s 9ms/step - loss: 0.1249 - acc: 0.9543\n",
            "466/466 [==============================] - 5s 10ms/step - loss: 0.1424 - acc: 0.9477\n",
            "466/466 [==============================] - 5s 11ms/step - loss: 0.1942 - acc: 0.9278\n",
            "466/466 [==============================] - 6s 14ms/step - loss: 0.1998 - acc: 0.9236\n",
            "466/466 [==============================] - 10s 22ms/step - loss: 0.1916 - acc: 0.9279\n",
            "466/466 [==============================] - 19s 41ms/step - loss: 0.1964 - acc: 0.9253\n",
            "1774/1774 [==============================] - 15s 9ms/step - loss: 0.1336 - acc: 0.9458\n",
            "1774/1774 [==============================] - 18s 10ms/step - loss: 0.1425 - acc: 0.9423\n",
            "1774/1774 [==============================] - 19s 11ms/step - loss: 0.1968 - acc: 0.9159\n",
            "1774/1774 [==============================] - 24s 14ms/step - loss: 0.2047 - acc: 0.9128\n",
            "1774/1774 [==============================] - 39s 22ms/step - loss: 0.1963 - acc: 0.9167\n",
            "1774/1774 [==============================] - 73s 41ms/step - loss: 0.1998 - acc: 0.9147\n",
            "349/349 [==============================] - 3s 9ms/step - loss: 0.0900 - acc: 0.9672\n",
            "349/349 [==============================] - 3s 10ms/step - loss: 0.0916 - acc: 0.9661\n",
            "349/349 [==============================] - 4s 11ms/step - loss: 0.1518 - acc: 0.9437\n",
            "349/349 [==============================] - 5s 14ms/step - loss: 0.1659 - acc: 0.9370\n",
            "349/349 [==============================] - 8s 22ms/step - loss: 0.1619 - acc: 0.9404\n",
            "349/349 [==============================] - 14s 41ms/step - loss: 0.1601 - acc: 0.9400\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 0.0853 - acc: 0.9693\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.0889 - acc: 0.9688\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.1371 - acc: 0.9521\n",
            "1563/1563 [==============================] - 22s 14ms/step - loss: 0.1440 - acc: 0.9490\n",
            "1563/1563 [==============================] - 35s 22ms/step - loss: 0.1406 - acc: 0.9505\n",
            "1563/1563 [==============================] - 64s 41ms/step - loss: 0.1393 - acc: 0.9496\n",
            "1181/1181 [==============================] - 10s 9ms/step - loss: 0.0919 - acc: 0.9662\n",
            "1181/1181 [==============================] - 12s 10ms/step - loss: 0.0949 - acc: 0.9649\n",
            "1181/1181 [==============================] - 13s 11ms/step - loss: 0.1515 - acc: 0.9433\n",
            "1181/1181 [==============================] - 16s 14ms/step - loss: 0.1542 - acc: 0.9405\n",
            "1181/1181 [==============================] - 26s 22ms/step - loss: 0.1528 - acc: 0.9411\n",
            "1181/1181 [==============================] - 48s 41ms/step - loss: 0.1502 - acc: 0.9426\n",
            "989/989 [==============================] - 9s 9ms/step - loss: 0.0767 - acc: 0.9716\n",
            "989/989 [==============================] - 10s 10ms/step - loss: 0.0779 - acc: 0.9711\n",
            "989/989 [==============================] - 11s 11ms/step - loss: 0.1279 - acc: 0.9501\n",
            "989/989 [==============================] - 14s 14ms/step - loss: 0.1345 - acc: 0.9479\n",
            "989/989 [==============================] - 22s 22ms/step - loss: 0.1270 - acc: 0.9522\n",
            "989/989 [==============================] - 41s 41ms/step - loss: 0.1282 - acc: 0.9503\n",
            "1992/1992 [==============================] - 17s 9ms/step - loss: 0.0929 - acc: 0.9640\n",
            "1992/1992 [==============================] - 19s 10ms/step - loss: 0.0943 - acc: 0.9628\n",
            "1992/1992 [==============================] - 22s 11ms/step - loss: 0.1424 - acc: 0.9439\n",
            "1992/1992 [==============================] - 27s 14ms/step - loss: 0.1432 - acc: 0.9438\n",
            "1992/1992 [==============================] - 44s 22ms/step - loss: 0.1395 - acc: 0.9448\n",
            "1992/1992 [==============================] - 81s 41ms/step - loss: 0.1416 - acc: 0.9441\n",
            "1070/1070 [==============================] - 9s 9ms/step - loss: 0.0759 - acc: 0.9731\n",
            "1070/1070 [==============================] - 10s 10ms/step - loss: 0.0750 - acc: 0.9723\n",
            "1070/1070 [==============================] - 12s 11ms/step - loss: 0.1172 - acc: 0.9593\n",
            "1070/1070 [==============================] - 15s 14ms/step - loss: 0.1205 - acc: 0.9569\n",
            "1070/1070 [==============================] - 24s 22ms/step - loss: 0.1152 - acc: 0.9585\n",
            "1070/1070 [==============================] - 44s 41ms/step - loss: 0.1159 - acc: 0.9576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYDcYsIOzzLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(models)):\n",
        "  models[i].save('model_vision_' + str(visions[i]) + '.h5')\n",
        "\n",
        "for i in range(len(models)):\n",
        "  files.download('model_vision_' + str(visions[i]) + '.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
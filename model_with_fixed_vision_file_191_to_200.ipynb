{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athensclub/Thai-Word-Cutter/blob/master/model_with_fixed_vision_file_191_to_200.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi2hBbnAEOhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports\n",
        "from google.colab import files\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Flatten,LSTM\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "#Create a mapping from a character to an integer\n",
        "characters = 'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืฺุู฿เแโใไๅๆ็่้๊๋์ํ๎๏๐๑๒๓๔๕๖๗๘๙abcdefghijklmnopqrstuvwxyz\"\\'0123456789,.!?/\\\\:;%()[]{}+_-*@#><=^$& \\t\\n'\n",
        "char_encode = {}\n",
        "char_decode = {}\n",
        "i = 1\n",
        "for c in characters:\n",
        "  char_encode[c] = i;\n",
        "  char_decode[i] = c;\n",
        "  i += 1\n",
        "\n",
        "def encode(data):\n",
        "  encoded = []\n",
        "  data = data.lower()\n",
        "  for c in data:\n",
        "    if c in char_encode:\n",
        "      encoded.append(char_encode[c])\n",
        "    else:\n",
        "      encoded.append(0) #unknown character\n",
        "  return encoded\n",
        "\n",
        "def decode(data):\n",
        "  decoded = ''\n",
        "  for c in data:\n",
        "    if c != 0:\n",
        "      decoded = decoded + char_decode[c]\n",
        "  return decoded\n",
        "\n",
        "#convert from raw data, a text which words are splitted by '|' will be converted\n",
        "#to a list of numver encoded by function encode and a list of the position of\n",
        "#where to cut the word\n",
        "def convert_data(data):\n",
        "  splitted = data.split('|')\n",
        "  encoded = encode(data.replace('|',''))\n",
        "  ans = np.zeros(len(encoded))\n",
        "  i = 0;\n",
        "  for s in splitted:\n",
        "    if(len(s) > 0):\n",
        "      i += len(s) \n",
        "      ans[i - 1] = 1\n",
        "  return encoded,ans\n",
        "\n",
        "#create a data for model with vision of length. used for training, evaluation, and predictions\n",
        "def create_model_data(encoded,ans,length):\n",
        "  before = []\n",
        "  current = []\n",
        "  after = []\n",
        "  temp = []\n",
        "  for i in range(len(encoded)):\n",
        "    temp.append(encoded[i])\n",
        "    a = []\n",
        "    b = []\n",
        "    for x in range(length):\n",
        "      if i - x - 1 >= 0:\n",
        "        a.insert(0,encoded[i-x-1])\n",
        "      if i + x + 1 < len(encoded):\n",
        "        b.append(encoded[i+x+1])\n",
        "    before.append(a)\n",
        "    current.append(temp.copy())\n",
        "    after.append(b)\n",
        "    if ans[i] == 1:\n",
        "      temp = []\n",
        "  return sequence.pad_sequences(before,length),sequence.pad_sequences(current,length),sequence.pad_sequences(after,length)\n",
        "\n",
        "#create a model with the vision of given length\n",
        "def create_model(length):\n",
        "  num_chars = len(characters)\n",
        "\n",
        "  before_input = Input(shape=(length,), name='before')  \n",
        "  current_input = Input(shape=(length,), name='current') \n",
        "  after_input = Input(shape=(length,), name='after')  \n",
        "\n",
        "  before_features = Embedding(num_chars, 64)(before_input)\n",
        "  current_features = Embedding(num_chars, 64)(current_input)\n",
        "  after_features = Embedding(num_chars, 64)(after_input)\n",
        "\n",
        "  before_features = LSTM(128)(before_features)\n",
        "  current_features = LSTM(128)(current_features)\n",
        "  after_features = LSTM(128)(after_features)\n",
        "\n",
        "  x = Concatenate()([before_features, current_features, after_features])\n",
        "  x = Dense(128,activation='relu')(x)\n",
        "  out = Dense(1,activation='sigmoid',name='output')(x)\n",
        "\n",
        "  model = Model(inputs=[before_input, current_input, after_input],\n",
        "                    outputs=[out])\n",
        "\n",
        "  model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['acc'])\n",
        "\n",
        "  return model\n",
        "\n",
        "#train the given model with the given vision length with the given raw data\n",
        "def train(model,data,length):\n",
        "  (encoded,ans) = convert_data(data)\n",
        "  (before,current,after) = create_model_data(encoded,ans,length)\n",
        "  model.fit([before,current,after],np.asarray(ans))\n",
        "\n",
        "#evaluate the given model with the given vision length with the given raw data\n",
        "def evaluate(model,data,length):\n",
        "  (encoded,ans) = convert_data(data)\n",
        "  (before,current,after) = create_model_data(encoded,ans,length)\n",
        "  model.evaluate([before,current,after],np.asarray(ans))\n",
        "\n",
        "visions = [10,20,30,50,100,200]\n",
        "models = []\n",
        "\n",
        "for v in visions:\n",
        "  models.append(create_model(v))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfy5S9AzsMgq",
        "colab_type": "code",
        "outputId": "6cd162b1-f7b0-43e4-b28d-7e5d372afae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(10):\n",
        "  target_file = open('train_{:05d}.txt'.format(i+191),'r')\n",
        "  if(target_file.mode == 'r'):\n",
        "    raw_data = target_file.read()\n",
        "  target_file.close()\n",
        "  for j in range(len(models)):\n",
        "    train(models[j],raw_data,visions[j])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "680/680 [==============================] - 6s 8ms/step - loss: 0.0314 - acc: 0.9885\n",
            "680/680 [==============================] - 7s 10ms/step - loss: 0.0335 - acc: 0.9877\n",
            "680/680 [==============================] - 7s 11ms/step - loss: 0.0569 - acc: 0.9782\n",
            "680/680 [==============================] - 9s 13ms/step - loss: 0.0557 - acc: 0.9798\n",
            "680/680 [==============================] - 13s 19ms/step - loss: 0.0550 - acc: 0.9807\n",
            "680/680 [==============================] - 22s 32ms/step - loss: 0.0568 - acc: 0.9788\n",
            "1274/1274 [==============================] - 11s 8ms/step - loss: 0.0379 - acc: 0.9855\n",
            "1274/1274 [==============================] - 12s 10ms/step - loss: 0.0389 - acc: 0.9854\n",
            "1274/1274 [==============================] - 14s 11ms/step - loss: 0.0825 - acc: 0.9692\n",
            "1274/1274 [==============================] - 17s 13ms/step - loss: 0.0835 - acc: 0.9681\n",
            "1274/1274 [==============================] - 25s 19ms/step - loss: 0.0847 - acc: 0.9681\n",
            "1274/1274 [==============================] - 41s 32ms/step - loss: 0.0826 - acc: 0.9694\n",
            "1657/1657 [==============================] - 14s 9ms/step - loss: 0.0519 - acc: 0.9809\n",
            "1657/1657 [==============================] - 16s 10ms/step - loss: 0.0529 - acc: 0.9807\n",
            "1657/1657 [==============================] - 18s 11ms/step - loss: 0.0863 - acc: 0.9660\n",
            "1657/1657 [==============================] - 22s 13ms/step - loss: 0.0863 - acc: 0.9667\n",
            "1657/1657 [==============================] - 32s 19ms/step - loss: 0.0867 - acc: 0.9664\n",
            "1657/1657 [==============================] - 53s 32ms/step - loss: 0.0876 - acc: 0.9661\n",
            "1313/1313 [==============================] - 11s 8ms/step - loss: 0.0536 - acc: 0.9810\n",
            "1313/1313 [==============================] - 13s 10ms/step - loss: 0.0548 - acc: 0.9808\n",
            "1313/1313 [==============================] - 14s 11ms/step - loss: 0.0922 - acc: 0.9652\n",
            "1313/1313 [==============================] - 17s 13ms/step - loss: 0.0935 - acc: 0.9645\n",
            "1313/1313 [==============================] - 25s 19ms/step - loss: 0.0940 - acc: 0.9649\n",
            "1313/1313 [==============================] - 42s 32ms/step - loss: 0.0928 - acc: 0.9651\n",
            "2173/2173 [==============================] - 18s 8ms/step - loss: 0.0250 - acc: 0.9912\n",
            "2173/2173 [==============================] - 21s 10ms/step - loss: 0.0270 - acc: 0.9910\n",
            "2173/2173 [==============================] - 24s 11ms/step - loss: 0.0575 - acc: 0.9780\n",
            "2173/2173 [==============================] - 28s 13ms/step - loss: 0.0556 - acc: 0.9789\n",
            "2173/2173 [==============================] - 42s 19ms/step - loss: 0.0567 - acc: 0.9788\n",
            "2173/2173 [==============================] - 70s 32ms/step - loss: 0.0570 - acc: 0.9786\n",
            "2115/2115 [==============================] - 18s 8ms/step - loss: 0.0410 - acc: 0.9849\n",
            "2115/2115 [==============================] - 20s 9ms/step - loss: 0.0432 - acc: 0.9844\n",
            "2115/2115 [==============================] - 23s 11ms/step - loss: 0.0784 - acc: 0.9692\n",
            "2115/2115 [==============================] - 28s 13ms/step - loss: 0.0788 - acc: 0.9693\n",
            "2115/2115 [==============================] - 41s 19ms/step - loss: 0.0802 - acc: 0.9693\n",
            "2115/2115 [==============================] - 68s 32ms/step - loss: 0.0805 - acc: 0.9686\n",
            "2637/2637 [==============================] - 22s 8ms/step - loss: 0.0322 - acc: 0.9888\n",
            "2637/2637 [==============================] - 25s 10ms/step - loss: 0.0339 - acc: 0.9880\n",
            "2637/2637 [==============================] - 28s 11ms/step - loss: 0.0645 - acc: 0.9757\n",
            "2637/2637 [==============================] - 34s 13ms/step - loss: 0.0640 - acc: 0.9750\n",
            "2637/2637 [==============================] - 51s 19ms/step - loss: 0.0636 - acc: 0.9751\n",
            "2637/2637 [==============================] - 85s 32ms/step - loss: 0.0657 - acc: 0.9745\n",
            "1816/1816 [==============================] - 15s 8ms/step - loss: 0.0428 - acc: 0.9845\n",
            "1816/1816 [==============================] - 17s 10ms/step - loss: 0.0449 - acc: 0.9836\n",
            "1816/1816 [==============================] - 19s 11ms/step - loss: 0.0727 - acc: 0.9712\n",
            "1816/1816 [==============================] - 24s 13ms/step - loss: 0.0725 - acc: 0.9722\n",
            "1816/1816 [==============================] - 35s 19ms/step - loss: 0.0737 - acc: 0.9708\n",
            "1816/1816 [==============================] - 59s 32ms/step - loss: 0.0741 - acc: 0.9713\n",
            "2313/2313 [==============================] - 20s 9ms/step - loss: 0.0289 - acc: 0.9899\n",
            "2313/2313 [==============================] - 22s 10ms/step - loss: 0.0338 - acc: 0.9881\n",
            "2313/2313 [==============================] - 26s 11ms/step - loss: 0.0592 - acc: 0.9769\n",
            "2313/2313 [==============================] - 30s 13ms/step - loss: 0.0601 - acc: 0.9773\n",
            "2313/2313 [==============================] - 45s 20ms/step - loss: 0.0607 - acc: 0.9762\n",
            "2313/2313 [==============================] - 74s 32ms/step - loss: 0.0602 - acc: 0.9764\n",
            "1800/1800 [==============================] - 15s 9ms/step - loss: 0.0445 - acc: 0.9834\n",
            "1800/1800 [==============================] - 17s 10ms/step - loss: 0.0472 - acc: 0.9826\n",
            "1800/1800 [==============================] - 20s 11ms/step - loss: 0.0807 - acc: 0.9699\n",
            "1800/1800 [==============================] - 24s 13ms/step - loss: 0.0829 - acc: 0.9690\n",
            "1800/1800 [==============================] - 35s 19ms/step - loss: 0.0829 - acc: 0.9684\n",
            "1800/1800 [==============================] - 58s 32ms/step - loss: 0.0830 - acc: 0.9690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYDcYsIOzzLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(models)):\n",
        "  models[i].save('model_vision_' + str(visions[i]) + '.h5')\n",
        "\n",
        "for i in range(len(models)):\n",
        "  files.download('model_vision_' + str(visions[i]) + '.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
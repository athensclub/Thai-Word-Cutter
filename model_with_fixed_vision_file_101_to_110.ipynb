{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athensclub/Thai-Word-Cutter/blob/master/model_with_fixed_vision_file_101_to_110.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi2hBbnAEOhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports\n",
        "from google.colab import files\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Flatten,LSTM\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "#Create a mapping from a character to an integer\n",
        "characters = 'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืฺุู฿เแโใไๅๆ็่้๊๋์ํ๎๏๐๑๒๓๔๕๖๗๘๙abcdefghijklmnopqrstuvwxyz\"\\'0123456789,.!?/\\\\:;%()[]{}+_-*@#><=^$& \\t\\n'\n",
        "char_encode = {}\n",
        "char_decode = {}\n",
        "i = 1\n",
        "for c in characters:\n",
        "  char_encode[c] = i;\n",
        "  char_decode[i] = c;\n",
        "  i += 1\n",
        "\n",
        "def encode(data):\n",
        "  encoded = []\n",
        "  data = data.lower()\n",
        "  for c in data:\n",
        "    if c in char_encode:\n",
        "      encoded.append(char_encode[c])\n",
        "    else:\n",
        "      encoded.append(0) #unknown character\n",
        "  return encoded\n",
        "\n",
        "def decode(data):\n",
        "  decoded = ''\n",
        "  for c in data:\n",
        "    if c != 0:\n",
        "      decoded = decoded + char_decode[c]\n",
        "  return decoded\n",
        "\n",
        "#convert from raw data, a text which words are splitted by '|' will be converted\n",
        "#to a list of numver encoded by function encode and a list of the position of\n",
        "#where to cut the word\n",
        "def convert_data(data):\n",
        "  splitted = data.split('|')\n",
        "  encoded = encode(data.replace('|',''))\n",
        "  ans = np.zeros(len(encoded))\n",
        "  i = 0;\n",
        "  for s in splitted:\n",
        "    if(len(s) > 0):\n",
        "      i += len(s) \n",
        "      ans[i - 1] = 1\n",
        "  return encoded,ans\n",
        "\n",
        "#create a data for model with vision of length. used for training, evaluation, and predictions\n",
        "def create_model_data(encoded,ans,length):\n",
        "  before = []\n",
        "  current = []\n",
        "  after = []\n",
        "  temp = []\n",
        "  for i in range(len(encoded)):\n",
        "    temp.append(encoded[i])\n",
        "    a = []\n",
        "    b = []\n",
        "    for x in range(length):\n",
        "      if i - x - 1 >= 0:\n",
        "        a.insert(0,encoded[i-x-1])\n",
        "      if i + x + 1 < len(encoded):\n",
        "        b.append(encoded[i+x+1])\n",
        "    before.append(a)\n",
        "    current.append(temp.copy())\n",
        "    after.append(b)\n",
        "    if ans[i] == 1:\n",
        "      temp = []\n",
        "  return sequence.pad_sequences(before,length),sequence.pad_sequences(current,length),sequence.pad_sequences(after,length)\n",
        "\n",
        "#create a model with the vision of given length\n",
        "def create_model(length):\n",
        "  num_chars = len(characters)\n",
        "\n",
        "  before_input = Input(shape=(length,), name='before')  \n",
        "  current_input = Input(shape=(length,), name='current') \n",
        "  after_input = Input(shape=(length,), name='after')  \n",
        "\n",
        "  before_features = Embedding(num_chars, 64)(before_input)\n",
        "  current_features = Embedding(num_chars, 64)(current_input)\n",
        "  after_features = Embedding(num_chars, 64)(after_input)\n",
        "\n",
        "  before_features = LSTM(128)(before_features)\n",
        "  current_features = LSTM(128)(current_features)\n",
        "  after_features = LSTM(128)(after_features)\n",
        "\n",
        "  x = Concatenate()([before_features, current_features, after_features])\n",
        "  x = Dense(128,activation='relu')(x)\n",
        "  out = Dense(1,activation='sigmoid',name='output')(x)\n",
        "\n",
        "  model = Model(inputs=[before_input, current_input, after_input],\n",
        "                    outputs=[out])\n",
        "\n",
        "  model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['acc'])\n",
        "\n",
        "  return model\n",
        "\n",
        "#train the given model with the given vision length with the given raw data\n",
        "def train(model,data,length):\n",
        "  (encoded,ans) = convert_data(data)\n",
        "  (before,current,after) = create_model_data(encoded,ans,length)\n",
        "  model.fit([before,current,after],np.asarray(ans))\n",
        "\n",
        "#evaluate the given model with the given vision length with the given raw data\n",
        "def evaluate(model,data,length):\n",
        "  (encoded,ans) = convert_data(data)\n",
        "  (before,current,after) = create_model_data(encoded,ans,length)\n",
        "  model.evaluate([before,current,after],np.asarray(ans))\n",
        "\n",
        "visions = [10,20,30,50,100,200]\n",
        "models = []\n",
        "\n",
        "for v in visions:\n",
        "  models.append(create_model(v))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfy5S9AzsMgq",
        "colab_type": "code",
        "outputId": "4409f50c-afaa-40bf-a686-26d4fb3e83d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(10):\n",
        "  target_file = open('train_{:05d}.txt'.format(i+101),'r')\n",
        "  if(target_file.mode == 'r'):\n",
        "    raw_data = target_file.read()\n",
        "  target_file.close()\n",
        "  for j in range(len(models)):\n",
        "    train(models[j],raw_data,visions[j])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2211/2211 [==============================] - 17s 8ms/step - loss: 0.2067 - acc: 0.9155\n",
            "2211/2211 [==============================] - 20s 9ms/step - loss: 0.2427 - acc: 0.8979\n",
            "2211/2211 [==============================] - 22s 10ms/step - loss: 0.2656 - acc: 0.8871\n",
            "2211/2211 [==============================] - 27s 12ms/step - loss: 0.2663 - acc: 0.8880\n",
            "2211/2211 [==============================] - 42s 19ms/step - loss: 0.2634 - acc: 0.8881\n",
            "2211/2211 [==============================] - 70s 32ms/step - loss: 0.2609 - acc: 0.8895\n",
            "1721/1721 [==============================] - 13s 8ms/step - loss: 0.1530 - acc: 0.9372\n",
            "1721/1721 [==============================] - 15s 9ms/step - loss: 0.1499 - acc: 0.9397\n",
            "1721/1721 [==============================] - 17s 10ms/step - loss: 0.2191 - acc: 0.9077\n",
            "1721/1721 [==============================] - 21s 12ms/step - loss: 0.2221 - acc: 0.9062\n",
            "1721/1721 [==============================] - 33s 19ms/step - loss: 0.2221 - acc: 0.9054\n",
            "1721/1721 [==============================] - 55s 32ms/step - loss: 0.2202 - acc: 0.9081\n",
            "1148/1148 [==============================] - 9s 8ms/step - loss: 0.1076 - acc: 0.9622\n",
            "1148/1148 [==============================] - 10s 9ms/step - loss: 0.1027 - acc: 0.9632\n",
            "1148/1148 [==============================] - 11s 10ms/step - loss: 0.1607 - acc: 0.9421\n",
            "1148/1148 [==============================] - 14s 12ms/step - loss: 0.1620 - acc: 0.9412\n",
            "1148/1148 [==============================] - 22s 19ms/step - loss: 0.1620 - acc: 0.9412\n",
            "1148/1148 [==============================] - 37s 32ms/step - loss: 0.1589 - acc: 0.9427\n",
            "462/462 [==============================] - 4s 8ms/step - loss: 0.0963 - acc: 0.9655\n",
            "462/462 [==============================] - 4s 9ms/step - loss: 0.0955 - acc: 0.9680\n",
            "462/462 [==============================] - 5s 10ms/step - loss: 0.1516 - acc: 0.9459\n",
            "462/462 [==============================] - 6s 12ms/step - loss: 0.1568 - acc: 0.9435\n",
            "462/462 [==============================] - 9s 19ms/step - loss: 0.1528 - acc: 0.9447\n",
            "462/462 [==============================] - 15s 32ms/step - loss: 0.1533 - acc: 0.9433\n",
            "1205/1205 [==============================] - 9s 8ms/step - loss: 0.0994 - acc: 0.9632\n",
            "1205/1205 [==============================] - 11s 9ms/step - loss: 0.0987 - acc: 0.9622\n",
            "1205/1205 [==============================] - 12s 10ms/step - loss: 0.1504 - acc: 0.9424\n",
            "1205/1205 [==============================] - 15s 12ms/step - loss: 0.1509 - acc: 0.9420\n",
            "1205/1205 [==============================] - 23s 19ms/step - loss: 0.1484 - acc: 0.9431\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.1525 - acc: 0.9428\n",
            "3436/3436 [==============================] - 27s 8ms/step - loss: 0.1023 - acc: 0.9593\n",
            "3436/3436 [==============================] - 30s 9ms/step - loss: 0.1021 - acc: 0.9591\n",
            "3436/3436 [==============================] - 34s 10ms/step - loss: 0.1481 - acc: 0.9420\n",
            "3436/3436 [==============================] - 42s 12ms/step - loss: 0.1485 - acc: 0.9404\n",
            "3436/3436 [==============================] - 65s 19ms/step - loss: 0.1468 - acc: 0.9417\n",
            "3436/3436 [==============================] - 111s 32ms/step - loss: 0.1489 - acc: 0.9407\n",
            "1537/1537 [==============================] - 12s 8ms/step - loss: 0.0947 - acc: 0.9650\n",
            "1537/1537 [==============================] - 14s 9ms/step - loss: 0.0896 - acc: 0.9669\n",
            "1537/1537 [==============================] - 15s 10ms/step - loss: 0.1375 - acc: 0.9486\n",
            "1537/1537 [==============================] - 19s 12ms/step - loss: 0.1366 - acc: 0.9481\n",
            "1537/1537 [==============================] - 29s 19ms/step - loss: 0.1371 - acc: 0.9480\n",
            "1537/1537 [==============================] - 49s 32ms/step - loss: 0.1365 - acc: 0.9475\n",
            "2400/2400 [==============================] - 19s 8ms/step - loss: 0.0800 - acc: 0.9689\n",
            "2400/2400 [==============================] - 21s 9ms/step - loss: 0.0768 - acc: 0.9706\n",
            "2400/2400 [==============================] - 24s 10ms/step - loss: 0.1151 - acc: 0.9571\n",
            "2400/2400 [==============================] - 30s 12ms/step - loss: 0.1153 - acc: 0.9562\n",
            "2400/2400 [==============================] - 46s 19ms/step - loss: 0.1142 - acc: 0.9570\n",
            "2400/2400 [==============================] - 77s 32ms/step - loss: 0.1156 - acc: 0.9560\n",
            "966/966 [==============================] - 7s 8ms/step - loss: 0.0718 - acc: 0.9733\n",
            "966/966 [==============================] - 9s 9ms/step - loss: 0.0712 - acc: 0.9731\n",
            "966/966 [==============================] - 10s 10ms/step - loss: 0.1139 - acc: 0.9570\n",
            "966/966 [==============================] - 12s 12ms/step - loss: 0.1180 - acc: 0.9581\n",
            "966/966 [==============================] - 18s 19ms/step - loss: 0.1174 - acc: 0.9574\n",
            "966/966 [==============================] - 31s 32ms/step - loss: 0.1202 - acc: 0.9563\n",
            "1561/1561 [==============================] - 12s 8ms/step - loss: 0.0782 - acc: 0.9717\n",
            "1561/1561 [==============================] - 14s 9ms/step - loss: 0.0783 - acc: 0.9724\n",
            "1561/1561 [==============================] - 16s 10ms/step - loss: 0.1244 - acc: 0.9552\n",
            "1561/1561 [==============================] - 20s 13ms/step - loss: 0.1244 - acc: 0.9531\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 0.1246 - acc: 0.9535\n",
            "1561/1561 [==============================] - 50s 32ms/step - loss: 0.1265 - acc: 0.9528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYDcYsIOzzLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(models)):\n",
        "  models[i].save('model_vision_' + str(visions[i]) + '.h5')\n",
        "\n",
        "for i in range(len(models)):\n",
        "  files.download('model_vision_' + str(visions[i]) + '.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
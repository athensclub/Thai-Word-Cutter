{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athensclub/Thai-Word-Cutter/blob/master/model_with_fixed_vision_file_171_to_180.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi2hBbnAEOhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports\n",
        "from google.colab import files\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Flatten,LSTM\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "#Create a mapping from a character to an integer\n",
        "characters = 'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืฺุู฿เแโใไๅๆ็่้๊๋์ํ๎๏๐๑๒๓๔๕๖๗๘๙abcdefghijklmnopqrstuvwxyz\"\\'0123456789,.!?/\\\\:;%()[]{}+_-*@#><=^$& \\t\\n'\n",
        "char_encode = {}\n",
        "char_decode = {}\n",
        "i = 1\n",
        "for c in characters:\n",
        "  char_encode[c] = i;\n",
        "  char_decode[i] = c;\n",
        "  i += 1\n",
        "\n",
        "def encode(data):\n",
        "  encoded = []\n",
        "  data = data.lower()\n",
        "  for c in data:\n",
        "    if c in char_encode:\n",
        "      encoded.append(char_encode[c])\n",
        "    else:\n",
        "      encoded.append(0) #unknown character\n",
        "  return encoded\n",
        "\n",
        "def decode(data):\n",
        "  decoded = ''\n",
        "  for c in data:\n",
        "    if c != 0:\n",
        "      decoded = decoded + char_decode[c]\n",
        "  return decoded\n",
        "\n",
        "#convert from raw data, a text which words are splitted by '|' will be converted\n",
        "#to a list of numver encoded by function encode and a list of the position of\n",
        "#where to cut the word\n",
        "def convert_data(data):\n",
        "  splitted = data.split('|')\n",
        "  encoded = encode(data.replace('|',''))\n",
        "  ans = np.zeros(len(encoded))\n",
        "  i = 0;\n",
        "  for s in splitted:\n",
        "    if(len(s) > 0):\n",
        "      i += len(s) \n",
        "      ans[i - 1] = 1\n",
        "  return encoded,ans\n",
        "\n",
        "#create a data for model with vision of length. used for training, evaluation, and predictions\n",
        "def create_model_data(encoded,ans,length):\n",
        "  before = []\n",
        "  current = []\n",
        "  after = []\n",
        "  temp = []\n",
        "  for i in range(len(encoded)):\n",
        "    temp.append(encoded[i])\n",
        "    a = []\n",
        "    b = []\n",
        "    for x in range(length):\n",
        "      if i - x - 1 >= 0:\n",
        "        a.insert(0,encoded[i-x-1])\n",
        "      if i + x + 1 < len(encoded):\n",
        "        b.append(encoded[i+x+1])\n",
        "    before.append(a)\n",
        "    current.append(temp.copy())\n",
        "    after.append(b)\n",
        "    if ans[i] == 1:\n",
        "      temp = []\n",
        "  return sequence.pad_sequences(before,length),sequence.pad_sequences(current,length),sequence.pad_sequences(after,length)\n",
        "\n",
        "#create a model with the vision of given length\n",
        "def create_model(length):\n",
        "  num_chars = len(characters)\n",
        "\n",
        "  before_input = Input(shape=(length,), name='before')  \n",
        "  current_input = Input(shape=(length,), name='current') \n",
        "  after_input = Input(shape=(length,), name='after')  \n",
        "\n",
        "  before_features = Embedding(num_chars, 64)(before_input)\n",
        "  current_features = Embedding(num_chars, 64)(current_input)\n",
        "  after_features = Embedding(num_chars, 64)(after_input)\n",
        "\n",
        "  before_features = LSTM(128)(before_features)\n",
        "  current_features = LSTM(128)(current_features)\n",
        "  after_features = LSTM(128)(after_features)\n",
        "\n",
        "  x = Concatenate()([before_features, current_features, after_features])\n",
        "  x = Dense(128,activation='relu')(x)\n",
        "  out = Dense(1,activation='sigmoid',name='output')(x)\n",
        "\n",
        "  model = Model(inputs=[before_input, current_input, after_input],\n",
        "                    outputs=[out])\n",
        "\n",
        "  model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['acc'])\n",
        "\n",
        "  return model\n",
        "\n",
        "#train the given model with the given vision length with the given raw data\n",
        "def train(model,data,length):\n",
        "  (encoded,ans) = convert_data(data)\n",
        "  (before,current,after) = create_model_data(encoded,ans,length)\n",
        "  model.fit([before,current,after],np.asarray(ans))\n",
        "\n",
        "#evaluate the given model with the given vision length with the given raw data\n",
        "def evaluate(model,data,length):\n",
        "  (encoded,ans) = convert_data(data)\n",
        "  (before,current,after) = create_model_data(encoded,ans,length)\n",
        "  model.evaluate([before,current,after],np.asarray(ans))\n",
        "\n",
        "visions = [10,20,30,50,100,200]\n",
        "models = []\n",
        "\n",
        "for v in visions:\n",
        "  models.append(create_model(v))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfy5S9AzsMgq",
        "colab_type": "code",
        "outputId": "18acf48b-713b-40c8-97be-0b05e30d0328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(10):\n",
        "  target_file = open('train_{:05d}.txt'.format(i+171),'r')\n",
        "  if(target_file.mode == 'r'):\n",
        "    raw_data = target_file.read()\n",
        "  target_file.close()\n",
        "  for j in range(len(models)):\n",
        "    train(models[j],raw_data,visions[j])\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1899/1899 [==============================] - 28s 15ms/step - loss: 0.2373 - acc: 0.8968\n",
            "1899/1899 [==============================] - 41s 22ms/step - loss: 0.2866 - acc: 0.8728\n",
            "1899/1899 [==============================] - 55s 29ms/step - loss: 0.2901 - acc: 0.8695\n",
            "1899/1899 [==============================] - 79s 42ms/step - loss: 0.2900 - acc: 0.8694\n",
            "1899/1899 [==============================] - 146s 77ms/step - loss: 0.2934 - acc: 0.8676\n",
            "1899/1899 [==============================] - 217s 114ms/step - loss: 0.2903 - acc: 0.8725\n",
            "712/712 [==============================] - 10s 14ms/step - loss: 0.1312 - acc: 0.9489\n",
            "712/712 [==============================] - 15s 22ms/step - loss: 0.1722 - acc: 0.9341\n",
            "712/712 [==============================] - 21s 29ms/step - loss: 0.1871 - acc: 0.9270\n",
            "712/712 [==============================] - 30s 42ms/step - loss: 0.1882 - acc: 0.9243\n",
            "712/712 [==============================] - 55s 77ms/step - loss: 0.1890 - acc: 0.9248\n",
            "712/712 [==============================] - 84s 117ms/step - loss: 0.1871 - acc: 0.9264\n",
            "306/306 [==============================] - 4s 13ms/step - loss: 0.1394 - acc: 0.9475\n",
            "306/306 [==============================] - 6s 21ms/step - loss: 0.1844 - acc: 0.9290\n",
            "306/306 [==============================] - 9s 29ms/step - loss: 0.2137 - acc: 0.9161\n",
            "306/306 [==============================] - 13s 41ms/step - loss: 0.2187 - acc: 0.9177\n",
            "306/306 [==============================] - 24s 77ms/step - loss: 0.2140 - acc: 0.9188\n",
            "306/306 [==============================] - 37s 121ms/step - loss: 0.2110 - acc: 0.9177\n",
            "701/701 [==============================] - 10s 15ms/step - loss: 0.1137 - acc: 0.9578\n",
            "701/701 [==============================] - 15s 22ms/step - loss: 0.1397 - acc: 0.9470\n",
            "701/701 [==============================] - 20s 29ms/step - loss: 0.1648 - acc: 0.9364\n",
            "701/701 [==============================] - 29s 42ms/step - loss: 0.1712 - acc: 0.9341\n",
            "701/701 [==============================] - 54s 77ms/step - loss: 0.1656 - acc: 0.9350\n",
            "701/701 [==============================] - 85s 122ms/step - loss: 0.1626 - acc: 0.9373\n",
            "2417/2417 [==============================] - 36s 15ms/step - loss: 0.0871 - acc: 0.9686\n",
            "2417/2417 [==============================] - 52s 22ms/step - loss: 0.0955 - acc: 0.9656\n",
            "2417/2417 [==============================] - 70s 29ms/step - loss: 0.1525 - acc: 0.9425\n",
            "2417/2417 [==============================] - 101s 42ms/step - loss: 0.1576 - acc: 0.9394\n",
            "2417/2417 [==============================] - 186s 77ms/step - loss: 0.1550 - acc: 0.9397\n",
            "2417/2417 [==============================] - 280s 116ms/step - loss: 0.1508 - acc: 0.9431\n",
            "1287/1287 [==============================] - 19s 14ms/step - loss: 0.0855 - acc: 0.9710\n",
            "1287/1287 [==============================] - 28s 22ms/step - loss: 0.0868 - acc: 0.9698\n",
            "1287/1287 [==============================] - 37s 29ms/step - loss: 0.1397 - acc: 0.9498\n",
            "1287/1287 [==============================] - 53s 42ms/step - loss: 0.1443 - acc: 0.9487\n",
            "1287/1287 [==============================] - 99s 77ms/step - loss: 0.1413 - acc: 0.9493\n",
            "1287/1287 [==============================] - 149s 116ms/step - loss: 0.1394 - acc: 0.9504\n",
            "1689/1689 [==============================] - 25s 15ms/step - loss: 0.0972 - acc: 0.9627\n",
            "1689/1689 [==============================] - 37s 22ms/step - loss: 0.0938 - acc: 0.9635\n",
            "1689/1689 [==============================] - 49s 29ms/step - loss: 0.1404 - acc: 0.9469\n",
            "1689/1689 [==============================] - 70s 42ms/step - loss: 0.1479 - acc: 0.9433\n",
            "1689/1689 [==============================] - 131s 78ms/step - loss: 0.1462 - acc: 0.9439\n",
            "1689/1689 [==============================] - 200s 118ms/step - loss: 0.1424 - acc: 0.9458\n",
            "879/879 [==============================] - 13s 15ms/step - loss: 0.0806 - acc: 0.9705\n",
            "879/879 [==============================] - 19s 22ms/step - loss: 0.0813 - acc: 0.9690\n",
            "879/879 [==============================] - 25s 29ms/step - loss: 0.1300 - acc: 0.9510\n",
            "879/879 [==============================] - 36s 41ms/step - loss: 0.1327 - acc: 0.9492\n",
            "879/879 [==============================] - 68s 77ms/step - loss: 0.1331 - acc: 0.9507\n",
            "879/879 [==============================] - 109s 124ms/step - loss: 0.1300 - acc: 0.9514\n",
            "2022/2022 [==============================] - 30s 15ms/step - loss: 0.0872 - acc: 0.9671\n",
            "2022/2022 [==============================] - 44s 22ms/step - loss: 0.0846 - acc: 0.9678\n",
            "2022/2022 [==============================] - 58s 29ms/step - loss: 0.1323 - acc: 0.9491\n",
            "2022/2022 [==============================] - 85s 42ms/step - loss: 0.1326 - acc: 0.9485\n",
            "2022/2022 [==============================] - 158s 78ms/step - loss: 0.1325 - acc: 0.9490\n",
            "2022/2022 [==============================] - 236s 117ms/step - loss: 0.1321 - acc: 0.9505\n",
            "1217/1217 [==============================] - 18s 15ms/step - loss: 0.0726 - acc: 0.9745\n",
            "1217/1217 [==============================] - 27s 22ms/step - loss: 0.0756 - acc: 0.9733\n",
            "1217/1217 [==============================] - 36s 29ms/step - loss: 0.1175 - acc: 0.9597\n",
            "1217/1217 [==============================] - 51s 42ms/step - loss: 0.1192 - acc: 0.9584\n",
            "1217/1217 [==============================] - 94s 78ms/step - loss: 0.1203 - acc: 0.9574\n",
            "1217/1217 [==============================] - 144s 118ms/step - loss: 0.1169 - acc: 0.9589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYDcYsIOzzLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(models)):\n",
        "  models[i].save('model_vision_' + str(visions[i]) + '.h5')\n",
        "\n",
        "for i in range(len(models)):\n",
        "  files.download('model_vision_' + str(visions[i]) + '.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
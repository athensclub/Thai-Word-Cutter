{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athensclub/Thai-Word-Cutter/blob/master/test_model_with_splitted_sentences.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_sVizY7dPOB",
        "colab_type": "text"
      },
      "source": [
        "# **Importing and Housekeeping**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQazv8NEPoSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Flatten,LSTM\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQh-zzkUjl06",
        "colab_type": "text"
      },
      "source": [
        "# **Create a mapping from a character to an integer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqoLfvapY1x9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "characters = 'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืฺุู฿เแโใไๅๆ็่้๊๋์ํ๎๏๐๑๒๓๔๕๖๗๘๙abcdefghijklmnopqrstuvwxyz\"\\'0123456789,.!?/\\\\:;%()[]{}+_-*@#><=^$& \\t\\n'\n",
        "char_encode = {}\n",
        "char_decode = {}\n",
        "i = 1\n",
        "for c in characters:\n",
        "  char_encode[c] = i;\n",
        "  char_decode[i] = c;\n",
        "  i += 1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCsv1F0AjwNm",
        "colab_type": "text"
      },
      "source": [
        "# **Function: `encode(data)`**\n",
        "\n",
        "> Accepts: (data)\n",
        "*   data: the string to be converted to list of integers.\n",
        "\n",
        "\n",
        "> Returns: (encoded)\n",
        "*   encoded: the list of integers encoded from the given data string\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkBNo0GehRS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(data):\n",
        "  encoded = []\n",
        "  data = data.lower()\n",
        "  for c in data:\n",
        "    encoded.append(char_encode[c])\n",
        "  return encoded"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4_-16tjlerZ",
        "colab_type": "text"
      },
      "source": [
        "# **Function: `decode(data)`**\n",
        "\n",
        "> Accepts: (data)\n",
        "*   data: the list of integers to be converted to string\n",
        "\n",
        "> Returns: (decoded)\n",
        "*   decoded: the string that is decoded from list of integers given from data\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc88P1L-lL1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode(data):\n",
        "  decoded = ''\n",
        "  for c in data:\n",
        "    if c != 0:\n",
        "      decoded = decoded + char_decode[c]\n",
        "  return decoded"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1NGb8obiad9",
        "colab_type": "text"
      },
      "source": [
        "# **Function: `convert_data(data)`**\n",
        "> Accepts: (data)\n",
        "*   data: raw string read from news file\n",
        "\n",
        "> Returns: (encoded,ans)\n",
        "*  encoded: The string that is created from removing separator '|' from original raw string, which is then encoded into integers by function ```encode(data)```\n",
        "*   ans: The array that is of the same length as combined string and has value be either 0 or 1. The 0 means that the character at that index of combined string should not be cut while 1 means that it should be cut\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roP1XwcWaR3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_data(data):\n",
        "  splitted = data.split('|')\n",
        "  encoded = encode(data.replace('|',''))\n",
        "  ans = np.zeros(len(encoded))\n",
        "  i = 0;\n",
        "  for s in splitted:\n",
        "    if(len(s) > 0):\n",
        "      i += len(s) \n",
        "      ans[i - 1] = 1\n",
        "  return encoded,ans"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi2TgMTnmTlP",
        "colab_type": "text"
      },
      "source": [
        "# **Function: `split_data(encoded,ans,length=256)`**\n",
        "A function that split by whitespace and then combine them together into array that the size does not exceed the length and return the result of combining all the combined all of the splitted data into one list, mapped to another answer array by index\n",
        "\n",
        "> Accepts: (encoded,ans,length=256)\n",
        "*   encoded: the encoded data that is going to be splitted\n",
        "*   ans: the array of the answer of the data\n",
        "*   length: the maximum size of each splitted data (default value is 256)\n",
        "\n",
        "> Returns: (splitted,splitted_ans)\n",
        "*   splitted: the list of the splitted data\n",
        "*   splitted_ans: the list of the answer to the splitted data, mapped by index\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfPPFOWLeGF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data(encoded,ans,length=256):\n",
        "  splitted = []\n",
        "  splitted_ans = []\n",
        "  ans_chunk = []\n",
        "  chunk = []\n",
        "  temp = []\n",
        "  ans_temp = []\n",
        "  for i in range(len(encoded)):\n",
        "    c = encoded[i]\n",
        "    temp.append(c)\n",
        "    ans_temp.append(ans[i])\n",
        "    if c == char_encode[' ']:\n",
        "      if len(temp) > 0:\n",
        "        if len(temp) + len(chunk) < length:\n",
        "          chunk.extend(temp)\n",
        "          ans_chunk.extend(ans_temp)\n",
        "          ans_temp = []\n",
        "          temp = []\n",
        "        else:\n",
        "          splitted.append(chunk)\n",
        "          splitted_ans.append(ans_chunk)\n",
        "          chunk = []\n",
        "          ans_chunk = []\n",
        "          chunk.extend(temp)\n",
        "          ans_chunk.extend(ans_temp)\n",
        "          ans_temp = []\n",
        "          temp = []\n",
        "  #cleaning leftovers\n",
        "  if len(temp) > 0:\n",
        "    if len(temp) + len(chunk) < length:\n",
        "      chunk.extend(temp)\n",
        "      ans_chunk.extend(ans_temp)\n",
        "    else:\n",
        "      splitted.append(chunk)\n",
        "      splitted_ans.append(ans_chunk)\n",
        "      chunk.extend(temp)\n",
        "      ans_chunk.extend(ans_temp)\n",
        "  if len(chunk) > 0:\n",
        "    splitted.append(chunk)\n",
        "    splitted_ans.append(ans_chunk)\n",
        "  return splitted,splitted_ans"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDkvaGNBoLeX",
        "colab_type": "text"
      },
      "source": [
        "# **Function: `split_text_data(encoded,length=256)`**\n",
        "Similar to ```split_data(encoded,ans,length=256)``` but does not split the answer data\n",
        "\n",
        "> Accepts: (encoded,length=256)\n",
        "*   encoded: the encoded data that is going to be splitted\n",
        "*   length: the maximum size of each splitted data (default value is 256)\n",
        "\n",
        "> Returns: (splitted)\n",
        "*   splitted: the list of the splitted data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp7TVJNgn9iJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_text_data(encoded,length=256):\n",
        "  splitted = []\n",
        "  chunk = []\n",
        "  temp = []\n",
        "  for i in range(len(encoded)):\n",
        "    c = encoded[i]\n",
        "    temp.append(c)\n",
        "    if c == char_encode[' ']:\n",
        "      if len(temp) > 0:\n",
        "        if len(temp) + len(chunk) < length:\n",
        "          chunk.extend(temp)\n",
        "          temp = []\n",
        "        else:\n",
        "          splitted.append(chunk)\n",
        "          chunk = []\n",
        "          chunk.extend(temp)\n",
        "          temp = []\n",
        "  #cleaning leftovers\n",
        "  if len(temp) > 0:\n",
        "    if len(temp) + len(chunk) < length:\n",
        "      chunk.extend(temp)\n",
        "    else:\n",
        "      splitted.append(chunk)\n",
        "      chunk.extend(temp)\n",
        "  if len(chunk) > 0:\n",
        "    splitted.append(chunk)\n",
        "  return splitted"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghAOM5HKhDuX",
        "colab_type": "text"
      },
      "source": [
        "# **Function: ```create_training_data(splitted,splitted_ans)```**\n",
        "Take in a list of chunks of text and where to cut and turn it into a training data\n",
        "\n",
        "> Accepts: (splitted,splitted_ans)\n",
        "*   splitted: The list of chunk of the text\n",
        "*   splitted_ans: the list of chunk of location to cut the text,mapped to the splitted chunk by index\n",
        "\n",
        "> Returns: (before,current,after,ans) Note that every data returned is mapped to one another by index\n",
        "*   before: the training data for model in 'before' input layer\n",
        "*   current: the training data for model in 'current' input layer\n",
        "*   after: the training data for model in 'after' input layer\n",
        "*   ans: the training data that contains answer for the model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKtml91vgCw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_training_data(splitted,splitted_ans):\n",
        "  before = []\n",
        "  current = []\n",
        "  after = []\n",
        "  ans = []\n",
        "  for i in range(len(splitted)):\n",
        "    chunk = splitted[i]\n",
        "    chunk_ans = splitted_ans[i]\n",
        "    temp = []\n",
        "    chunk_before = []\n",
        "    chunk_after = chunk.copy()\n",
        "    for j in range(len(chunk)):\n",
        "      temp = temp.copy()\n",
        "      temp.append(chunk[j])\n",
        "      chunk_after = chunk_after.copy()\n",
        "      chunk_after.pop(0)\n",
        "      before.append(chunk_before)\n",
        "      current.append(temp)\n",
        "      after.append(chunk_after)\n",
        "      ans.append(chunk_ans[j])\n",
        "      if chunk_ans[j] == 1:\n",
        "        chunk_before = chunk_before.copy()\n",
        "        chunk_before.extend(temp)\n",
        "        temp = []\n",
        "    if len(temp) > 0:\n",
        "      before.append(chunk_before)\n",
        "      current.append(temp)\n",
        "      after.append(chunk_after)\n",
        "      ans.append(chunk_ans[len(chunk_ans)-1])\n",
        "  before = sequence.pad_sequences(before,256)\n",
        "  current = sequence.pad_sequences(current,256)\n",
        "  after = sequence.pad_sequences(after,256)\n",
        "  return before,current,after,np.asarray(ans)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1qtVd28e0sr",
        "colab_type": "text"
      },
      "source": [
        "# **Function: ```train(_model,text)```**\n",
        "Train the given model using the input text that is tokenized, splitting each word by the character '|'\n",
        "\n",
        "> Accepts (_model,text)\n",
        "*   _model: the model that is going to be trained\n",
        "*   text: the raw text data that is tokenized, splitting each word by the character '|'\n",
        "\n",
        "> Returns: None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHYKdsUrXGLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(_model,text):\n",
        "  (train_encoded,train_ans) = convert_data(text)\n",
        "  (train_splitted,train_splitted_ans) = split_data(train_encoded,train_ans)\n",
        "  (train_data_before,train_data_current,train_data_after,train_data_ans) = create_training_data(train_splitted,train_splitted_ans)\n",
        "  _model.fit([train_data_before,train_data_current,train_data_after],train_data_ans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmdVxVOZgwOU",
        "colab_type": "text"
      },
      "source": [
        "# **Function: ```evaluate(_model,text)```**\n",
        "Simular to ```train(_model,text)``` but instead of using the given text data to train the model, it is used to evaluate the model\n",
        "\n",
        "\n",
        "\n",
        "> Accepts (_model,text)\n",
        "*   _model: the model that is going to be evaluated\n",
        "*   text: the raw text data that is tokenized, splitting each word by the character '|'\n",
        "\n",
        "> Returns: (result)\n",
        "*   result: Result of the evaluation. A list of 2 elements, the first element is loss, and the second element is accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRnnXzLlffc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@timed\n",
        "def evaluate(_model,text):\n",
        "  (train_encoded,train_ans) = convert_data(text)\n",
        "  (train_splitted,train_splitted_ans) = split_data(train_encoded,train_ans)\n",
        "  (train_data_before,train_data_current,train_data_after,train_data_ans) = create_training_data(train_splitted,train_splitted_ans)\n",
        "  result = _model.evaluate([train_data_before,train_data_current,train_data_after],train_data_ans)\n",
        "  return result"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lbHjJgFnWav",
        "colab_type": "text"
      },
      "source": [
        "# **Create and compile the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJEXKFcJEKcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.load_model('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xUa44gonbjI",
        "colab_type": "text"
      },
      "source": [
        "# **Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qljFfWdIEn9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(80):\n",
        "  file = open('news_{:05d}.txt'.format(i+1))\n",
        "  if file.mode == 'r':\n",
        "    train_text = file.read()\n",
        "  file.close()\n",
        "  train(model,train_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFkFnLxtbKR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxWmM8ND7SWX",
        "colab_type": "text"
      },
      "source": [
        "# **Evaluate the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ37G6HK6PBZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1207d569-f962-4160-bb08-453bfc38c40f"
      },
      "source": [
        "raw_data = \"\";\n",
        "for i in range(5):\n",
        "  target_file = open('train_{:05d}.txt'.format(445+1),'r')\n",
        "  if(target_file.mode == 'r'):\n",
        "    raw_data += target_file.read()\n",
        "  target_file.close()\n",
        "evaluate(model,raw_data)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2374/2374 [==============================] - 35s 15ms/step - loss: 0.0403 - acc: 0.9855\n",
            "evaluate took 37.352768898010254 seconds to complete its execution.\n",
            "[0.04034298658370972, 0.9855148792266846]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqPm8qXHfhiK",
        "colab_type": "text"
      },
      "source": [
        "# **Function: ```tokenize(text)```**\n",
        "Take in a normal string and tokenize it. Each sentence length must be below 256 characters and each sentence must be splitted by space bar\n",
        "\n",
        "> Accepts: (text)\n",
        "*   text: the raw text that is going to be tokenized\n",
        "\n",
        "> Returns: (tokenized)\n",
        "*   tokenized: the result of tokenization, in form of list of strings, where each string is the word tokenized\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2N4sdRVnnsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "  tokenized = []\n",
        "  splitted = split_text_data(encode(text))\n",
        "  for chunk in splitted:\n",
        "    temp = []\n",
        "    before = []\n",
        "    after = chunk.copy()\n",
        "    for c in chunk:\n",
        "      temp.append(c)\n",
        "      after.pop(0)\n",
        "      pred = model.predict([sequence.pad_sequences([before],256),sequence.pad_sequences([temp],256),sequence.pad_sequences([after],256)])[0]\n",
        "      if pred > 0.5:\n",
        "        tokenized.append(decode(temp))\n",
        "        before.extend(temp)\n",
        "        temp = []\n",
        "    #cleaning leftovers\n",
        "    if len(temp) > 0:\n",
        "      tokenized.append(decode(temp))\n",
        "  return tokenized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOk07fftp-M-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def timed(func):\n",
        "   def function_timer(*args, **kwargs):\n",
        "      start = time.time()\n",
        "      value = func(*args, **kwargs)\n",
        "      end = time.time()\n",
        "      runtime = end - start\n",
        "      msg = \"{func} took {time} seconds to complete its execution.\"\n",
        "      print(msg.format(func = func.__name__,time = runtime))\n",
        "      print(value)\n",
        "   return function_timer"
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}
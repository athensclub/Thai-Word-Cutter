{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athensclub/Thai-Word-Cutter/blob/master/model_with_fixed_vision_file_181_to_190.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi2hBbnAEOhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports\n",
        "from google.colab import files\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Flatten,LSTM\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "#Create a mapping from a character to an integer\n",
        "characters = 'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืฺุู฿เแโใไๅๆ็่้๊๋์ํ๎๏๐๑๒๓๔๕๖๗๘๙abcdefghijklmnopqrstuvwxyz\"\\'0123456789,.!?/\\\\:;%()[]{}+_-*@#><=^$& \\t\\n'\n",
        "char_encode = {}\n",
        "char_decode = {}\n",
        "i = 1\n",
        "for c in characters:\n",
        "  char_encode[c] = i;\n",
        "  char_decode[i] = c;\n",
        "  i += 1\n",
        "\n",
        "def encode(data):\n",
        "  encoded = []\n",
        "  data = data.lower()\n",
        "  for c in data:\n",
        "    if c in char_encode:\n",
        "      encoded.append(char_encode[c])\n",
        "    else:\n",
        "      encoded.append(0) #unknown character\n",
        "  return encoded\n",
        "\n",
        "def decode(data):\n",
        "  decoded = ''\n",
        "  for c in data:\n",
        "    if c != 0:\n",
        "      decoded = decoded + char_decode[c]\n",
        "  return decoded\n",
        "\n",
        "#convert from raw data, a text which words are splitted by '|' will be converted\n",
        "#to a list of numver encoded by function encode and a list of the position of\n",
        "#where to cut the word\n",
        "def convert_data(data):\n",
        "  splitted = data.split('|')\n",
        "  encoded = encode(data.replace('|',''))\n",
        "  ans = np.zeros(len(encoded))\n",
        "  i = 0;\n",
        "  for s in splitted:\n",
        "    if(len(s) > 0):\n",
        "      i += len(s) \n",
        "      ans[i - 1] = 1\n",
        "  return encoded,ans\n",
        "\n",
        "#create a data for model with vision of length. used for training, evaluation, and predictions\n",
        "def create_model_data(encoded,ans,length):\n",
        "  before = []\n",
        "  current = []\n",
        "  after = []\n",
        "  temp = []\n",
        "  for i in range(len(encoded)):\n",
        "    temp.append(encoded[i])\n",
        "    a = []\n",
        "    b = []\n",
        "    for x in range(length):\n",
        "      if i - x - 1 >= 0:\n",
        "        a.insert(0,encoded[i-x-1])\n",
        "      if i + x + 1 < len(encoded):\n",
        "        b.append(encoded[i+x+1])\n",
        "    before.append(a)\n",
        "    current.append(temp.copy())\n",
        "    after.append(b)\n",
        "    if ans[i] == 1:\n",
        "      temp = []\n",
        "  return sequence.pad_sequences(before,length),sequence.pad_sequences(current,length),sequence.pad_sequences(after,length)\n",
        "\n",
        "#create a model with the vision of given length\n",
        "def create_model(length):\n",
        "  num_chars = len(characters)\n",
        "\n",
        "  before_input = Input(shape=(length,), name='before')  \n",
        "  current_input = Input(shape=(length,), name='current') \n",
        "  after_input = Input(shape=(length,), name='after')  \n",
        "\n",
        "  before_features = Embedding(num_chars, 64)(before_input)\n",
        "  current_features = Embedding(num_chars, 64)(current_input)\n",
        "  after_features = Embedding(num_chars, 64)(after_input)\n",
        "\n",
        "  before_features = LSTM(128)(before_features)\n",
        "  current_features = LSTM(128)(current_features)\n",
        "  after_features = LSTM(128)(after_features)\n",
        "\n",
        "  x = Concatenate()([before_features, current_features, after_features])\n",
        "  x = Dense(128,activation='relu')(x)\n",
        "  out = Dense(1,activation='sigmoid',name='output')(x)\n",
        "\n",
        "  model = Model(inputs=[before_input, current_input, after_input],\n",
        "                    outputs=[out])\n",
        "\n",
        "  model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['acc'])\n",
        "\n",
        "  return model\n",
        "\n",
        "#train the given model with the given vision length with the given raw data\n",
        "def train(model,data,length):\n",
        "  (encoded,ans) = convert_data(data)\n",
        "  (before,current,after) = create_model_data(encoded,ans,length)\n",
        "  model.fit([before,current,after],np.asarray(ans))\n",
        "\n",
        "#evaluate the given model with the given vision length with the given raw data\n",
        "def evaluate(model,data,length):\n",
        "  (encoded,ans) = convert_data(data)\n",
        "  (before,current,after) = create_model_data(encoded,ans,length)\n",
        "  model.evaluate([before,current,after],np.asarray(ans))\n",
        "\n",
        "visions = [10,20,30,50,100,200]\n",
        "models = []\n",
        "\n",
        "for v in visions:\n",
        "  models.append(create_model(v))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfy5S9AzsMgq",
        "colab_type": "code",
        "outputId": "85224e0e-ce1a-40a4-d45e-579381971d7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(10):\n",
        "  target_file = open('train_{:05d}.txt'.format(i+181),'r')\n",
        "  if(target_file.mode == 'r'):\n",
        "    raw_data = target_file.read()\n",
        "  target_file.close()\n",
        "  for j in range(len(models)):\n",
        "    train(models[j],raw_data,visions[j])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "855/855 [==============================] - 13s 15ms/step - loss: 0.0771 - acc: 0.9721\n",
            "855/855 [==============================] - 19s 22ms/step - loss: 0.0724 - acc: 0.9744\n",
            "855/855 [==============================] - 25s 29ms/step - loss: 0.1137 - acc: 0.9580\n",
            "855/855 [==============================] - 35s 41ms/step - loss: 0.1174 - acc: 0.9567\n",
            "855/855 [==============================] - 66s 77ms/step - loss: 0.1161 - acc: 0.9568\n",
            "855/855 [==============================] - 102s 120ms/step - loss: 0.1133 - acc: 0.9579\n",
            "2465/2465 [==============================] - 37s 15ms/step - loss: 0.0722 - acc: 0.9736\n",
            "2465/2465 [==============================] - 54s 22ms/step - loss: 0.0708 - acc: 0.9741\n",
            "2465/2465 [==============================] - 72s 29ms/step - loss: 0.1161 - acc: 0.9567\n",
            "2465/2465 [==============================] - 104s 42ms/step - loss: 0.1164 - acc: 0.9575\n",
            "2465/2465 [==============================] - 191s 77ms/step - loss: 0.1153 - acc: 0.9572\n",
            "2465/2465 [==============================] - 285s 116ms/step - loss: 0.1141 - acc: 0.9582\n",
            "1502/1502 [==============================] - 22s 15ms/step - loss: 0.0686 - acc: 0.9741\n",
            "1502/1502 [==============================] - 33s 22ms/step - loss: 0.0650 - acc: 0.9763\n",
            "1502/1502 [==============================] - 44s 29ms/step - loss: 0.1005 - acc: 0.9630\n",
            "1502/1502 [==============================] - 62s 42ms/step - loss: 0.1028 - acc: 0.9614\n",
            "1502/1502 [==============================] - 116s 77ms/step - loss: 0.1022 - acc: 0.9613\n",
            "1502/1502 [==============================] - 180s 120ms/step - loss: 0.1018 - acc: 0.9613\n",
            "514/514 [==============================] - 7s 14ms/step - loss: 0.0757 - acc: 0.9714\n",
            "514/514 [==============================] - 11s 22ms/step - loss: 0.0705 - acc: 0.9745\n",
            "514/514 [==============================] - 15s 29ms/step - loss: 0.1133 - acc: 0.9581\n",
            "514/514 [==============================] - 21s 41ms/step - loss: 0.1145 - acc: 0.9570\n",
            "514/514 [==============================] - 40s 77ms/step - loss: 0.1118 - acc: 0.9588\n",
            "514/514 [==============================] - 60s 117ms/step - loss: 0.1087 - acc: 0.9572\n",
            "839/839 [==============================] - 12s 14ms/step - loss: 0.0641 - acc: 0.9773\n",
            "839/839 [==============================] - 18s 22ms/step - loss: 0.0614 - acc: 0.9782\n",
            "839/839 [==============================] - 24s 29ms/step - loss: 0.1162 - acc: 0.9574\n",
            "839/839 [==============================] - 35s 42ms/step - loss: 0.1145 - acc: 0.9577\n",
            "839/839 [==============================] - 65s 77ms/step - loss: 0.1158 - acc: 0.9588\n",
            "839/839 [==============================] - 97s 116ms/step - loss: 0.1133 - acc: 0.9591\n",
            "497/497 [==============================] - 7s 13ms/step - loss: 0.0603 - acc: 0.9795\n",
            "497/497 [==============================] - 11s 22ms/step - loss: 0.0597 - acc: 0.9781\n",
            "497/497 [==============================] - 14s 29ms/step - loss: 0.1101 - acc: 0.9590\n",
            "497/497 [==============================] - 21s 41ms/step - loss: 0.1068 - acc: 0.9610\n",
            "497/497 [==============================] - 38s 77ms/step - loss: 0.1062 - acc: 0.9623\n",
            "497/497 [==============================] - 61s 123ms/step - loss: 0.1076 - acc: 0.9613\n",
            "1028/1028 [==============================] - 15s 15ms/step - loss: 0.0437 - acc: 0.9850\n",
            "1028/1028 [==============================] - 22s 22ms/step - loss: 0.0430 - acc: 0.9849\n",
            "1028/1028 [==============================] - 30s 29ms/step - loss: 0.0722 - acc: 0.9741\n",
            "1028/1028 [==============================] - 43s 42ms/step - loss: 0.0734 - acc: 0.9740\n",
            "1028/1028 [==============================] - 79s 77ms/step - loss: 0.0730 - acc: 0.9744\n",
            "1028/1028 [==============================] - 125s 121ms/step - loss: 0.0707 - acc: 0.9748\n",
            "986/986 [==============================] - 14s 15ms/step - loss: 0.0431 - acc: 0.9858\n",
            "986/986 [==============================] - 22s 22ms/step - loss: 0.0441 - acc: 0.9851\n",
            "986/986 [==============================] - 28s 29ms/step - loss: 0.0709 - acc: 0.9744\n",
            "986/986 [==============================] - 41s 42ms/step - loss: 0.0711 - acc: 0.9752\n",
            "986/986 [==============================] - 76s 77ms/step - loss: 0.0722 - acc: 0.9745\n",
            "986/986 [==============================] - 116s 118ms/step - loss: 0.0716 - acc: 0.9742\n",
            "545/545 [==============================] - 8s 14ms/step - loss: 0.0710 - acc: 0.9756\n",
            "545/545 [==============================] - 12s 22ms/step - loss: 0.0699 - acc: 0.9756\n",
            "545/545 [==============================] - 16s 29ms/step - loss: 0.1101 - acc: 0.9600\n",
            "545/545 [==============================] - 23s 42ms/step - loss: 0.1124 - acc: 0.9583\n",
            "545/545 [==============================] - 42s 77ms/step - loss: 0.1120 - acc: 0.9595\n",
            "545/545 [==============================] - 66s 121ms/step - loss: 0.1093 - acc: 0.9599\n",
            "2840/2840 [==============================] - 43s 15ms/step - loss: 0.0601 - acc: 0.9784\n",
            "2840/2840 [==============================] - 62s 22ms/step - loss: 0.0594 - acc: 0.9790\n",
            "2840/2840 [==============================] - 82s 29ms/step - loss: 0.0988 - acc: 0.9644\n",
            "2840/2840 [==============================] - 118s 42ms/step - loss: 0.0992 - acc: 0.9641\n",
            "2840/2840 [==============================] - 219s 77ms/step - loss: 0.0979 - acc: 0.9642\n",
            "2840/2840 [==============================] - 318s 112ms/step - loss: 0.0986 - acc: 0.9640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYDcYsIOzzLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(models)):\n",
        "  models[i].save('model_vision_' + str(visions[i]) + '.h5')\n",
        "\n",
        "for i in range(len(models)):\n",
        "  files.download('model_vision_' + str(visions[i]) + '.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}